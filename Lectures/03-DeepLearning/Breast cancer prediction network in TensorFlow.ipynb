{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer prediction network with TensorFlow\n",
    "\n",
    "To further understand how to use TensorFlow, let's apply it to the breast cancer dataset we used in our earlier deep learning tutorial. First we read and normalize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "y = np.matrix(data.target).T\n",
    "X = np.matrix(data.data)\n",
    "M = X.shape[0]\n",
    "N = X.shape[1]\n",
    "\n",
    "# Normalize each input feature\n",
    "\n",
    "def normalize(X):\n",
    "    M = X.shape[0]\n",
    "    XX = X - np.tile(np.mean(X,0),[M,1])\n",
    "    XX = np.divide(XX, np.tile(np.std(XX,0),[M,1]))\n",
    "    return XX\n",
    "\n",
    "XX = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's build the DNN classifier, train it for 1000 mini-batches of size 20, and show the accuracy on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzd76scpm\n",
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_service': None, '_task_type': 'worker', '_master': '', '_task_id': 0, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_evaluation_master': '', '_session_config': None, '_model_dir': '/tmp/tmpzd76scpm', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f08722f8b00>, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpzd76scpm/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 12.363866\n",
      "INFO:tensorflow:global_step/sec: 671.34\n",
      "INFO:tensorflow:step = 101, loss = 0.9374872 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 1054.88\n",
      "INFO:tensorflow:step = 201, loss = 0.85170835 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1118.62\n",
      "INFO:tensorflow:step = 301, loss = 0.1886206 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1138.76\n",
      "INFO:tensorflow:step = 401, loss = 2.6761806 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1251.41\n",
      "INFO:tensorflow:step = 501, loss = 0.4092135 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1149.51\n",
      "INFO:tensorflow:step = 601, loss = 1.6705935 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 985.219\n",
      "INFO:tensorflow:step = 701, loss = 0.37439933 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 889.24\n",
      "INFO:tensorflow:step = 801, loss = 0.16639031 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 985.698\n",
      "INFO:tensorflow:step = 901, loss = 0.116965555 (0.101 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpzd76scpm/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.35557526.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-20-07:23:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzd76scpm/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-20-07:23:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9947276, accuracy_baseline = 0.6274165, auc = 0.99986124, auc_precision_recall = 0.99991685, average_loss = 0.016797569, global_step = 1000, label/mean = 0.6274165, loss = 0.016797569, prediction/mean = 0.62674326\n",
      "\n",
      "Train set accuracy: 0.995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Build classifier\n",
    "\n",
    "N = XX.shape[1]\n",
    "my_feature_columns = [tf.feature_column.numeric_column(key=(\"F%d\"%i)) for i in range(N)]\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[6, 5],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=2)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "batch_size = 20\n",
    "train_steps = 1000\n",
    "\n",
    "def make_dataset(X,y):\n",
    "    # Make a dictionary mapping feature index to the values for each feature\n",
    "    dictionary = { \"F%d\"%i: XX[:,i] for i in range(N) }\n",
    "    # Convert pairs from the dictionary and the label vector y to a dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dictionary, y))\n",
    "    return dataset\n",
    "    \n",
    "def input_fn_train():\n",
    "    dataset = make_dataset(XX,y)\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    # Build the Iterator, and return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "classifier.train(input_fn=input_fn_train, steps=train_steps)\n",
    "\n",
    "# Evaluate the model (on the training set!)\n",
    "\n",
    "def input_fn_eval():\n",
    "    dataset = make_dataset(XX,y)\n",
    "    return dataset.batch(1)\n",
    "\n",
    "eval_result = classifier.evaluate(input_fn=input_fn_eval)\n",
    "\n",
    "print('\\nTrain set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a training set accuracy of 99% or so.\n",
    "\n",
    "The next step would be to split the data into training and validation sets to find a good set of parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
