{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fd02f97b8061c0384f8bbf628447348",
     "grade": false,
     "grade_id": "cell-a76a50f786728ccb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lab 02: Nonlinear Regression and Overfitting\n",
    "\n",
    "In Lab 01, we explored the construction of linear regression models. Recall the assumptions we make in linear regression:\n",
    "- $\\textbf{x} \\in {\\cal X} = \\mathbb{R}^n$\n",
    "- $y \\in {\\cal Y} = \\mathbb{R}$\n",
    "- The $\\textbf{x}$ data are drawn i.i.d. from some (unknown) distribution over ${\\cal X}$\n",
    "- There is a linear relationship between $\\textbf{x}$ and $y$ with additive constant-variance Gaussian noise, i.e., $y \\sim {\\cal N}(\\theta^\\top \\textbf{x}, \\sigma^2)$,\n",
    "  where $\\theta \\in \\mathbb{R}^{n+1}$ is unknown and $\\textbf{x}$ is an $n+1$-dimensional vector augemented with a constant value of 1 as its first element.\n",
    "\n",
    "Today, we consider what we might do when the fourth assumption, linearity, does not hold. We introduce a particular form of nonlinear regression,\n",
    "*polynomial regression*, in which we account for nonlinear relationships between $\\mathbf{x}$ and $y$ by performing nonlinear transformations of\n",
    "the input variables in $\\mathbf{x}$.\n",
    "\n",
    "As an example, if we had a single input variable $x$, linear regression gives us the hypothesis\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x .$$\n",
    "We can add a new \"variable\" $x^2$, which is a nonlinear transformation of the input $x$:\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 .$$\n",
    "The important thing to notice here is that although the hypothesis is *nonlinear* in $x$, allowing us to model a more complex function than\n",
    "ordinary linear regression, the hypothesis is *linear* in $\\theta$, allowing us to use the normal equations to find the optimal $\\theta$ as before.\n",
    "\n",
    "## Polynomial Regression\n",
    "\n",
    "More generally, polynomial regession is a form of linear regression in which the relationship between the independent variables $\\mathbf{x}$ and the dependent\n",
    "variable $y$ is modelled as a polynomial.\n",
    "\n",
    "For a single input $x$, the hypothesis in a polynomial regression of degree $d$ is\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\cdots + \\theta_d x^d$$\n",
    "$$h_\\theta(x) = \\sum_{i=0}^{d} \\theta_i x^i$$\n",
    "\n",
    "For a multivariate input $\\mathbf{x}$, we introduce terms corresponding to every degree-$d$\n",
    "combination of factors. For example, if $n=3$ and $d=2$, we have\n",
    "$$h_\\theta(\\mathbf{x}) = \\theta_0\n",
    "                       + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3\n",
    "                       + \\theta_4 x_1^2 + \\theta_5 x_1 x_2 + \\theta_6 x_1 x_3\n",
    "                       + \\theta_7 x_2^2 + \\theta_8 x_2 x_3 + \\theta_9 x_3^2 .$$\n",
    "\n",
    "## Example 1: Synthetic data with a quadratic nonlinearity\n",
    "\n",
    "Let's take a look at how polynomial regression as compared to simple linear regression model works for data with a\n",
    "simple quadratic nonlinearity.\n",
    "\n",
    "### Generate a synthetic dataset\n",
    "\n",
    "First, we generate 100 observations from a ground truth quadratic function with Gaussian noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# please do not change the random seed, or the autograder's result checking will be wrong!\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X\n",
    "m = 100\n",
    "X = np.random.uniform(-4, 4, (m,1))\n",
    "\n",
    "# Generate y\n",
    "a = 0.7\n",
    "b = 1\n",
    "c = 2\n",
    "y = a * X**2 + b * X + c + np.random.randn(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(X, y, 'b.')\n",
    "plt.title('Polynomial regression example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3248ca198577ce931c964ef4c842a638",
     "grade": false,
     "grade_id": "cell-0ab271629541a02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implement the hypothesis function\n",
    "\n",
    "First, we will use ordinary linear regression:\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x$$\n",
    "Then, we use polynomial regression with $d=2$:\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 $$ \n",
    "In either case, by letting the input vector $\\bf{x} = \\begin{bmatrix} 1 \\\\ x \\end{bmatrix}$\n",
    "or $\\bf{x} = \\begin{bmatrix} 1 \\\\ x \\\\ x^2 \\end{bmatrix}$\n",
    "appropriately, the hypothesis can be written\n",
    "$$ h_\\mathbf{\\theta}(\\mathbf{x}) = \\mathbf{\\theta}^\\top \\mathbf{x} . $$\n",
    "\n",
    "Let's implement this hypothesis function in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, theta):\n",
    "    return X.dot(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd4984dde556e7c966eb2a195e267141",
     "grade": false,
     "grade_id": "cell-8b0f0421e3d03895",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implement the regression function (normal equations)\n",
    "\n",
    "Recall the normal equations used to find the $\\theta$ minimizing $J(\\theta)$\n",
    "when the design matrix $\\mathtt{X}_{m\\times(n+1)}$ contains one row for each example and\n",
    "$\\mathbf{y}$ is a column vector:\n",
    "$$\\mathbf{\\theta} = (\\mathtt{X}^\\top \\mathtt{X})^{-1}\\mathtt{X}^\\top\\mathbf{y}$$\n",
    "\n",
    "Let's implement the normal equations in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X, y):\n",
    "    cov = np.dot(X.T, X)\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    theta = np.dot(cov_inv, np.dot(X.T, y))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "926fdb2a3c6ca50772429e2576b3efa5",
     "grade": false,
     "grade_id": "cell-930cc2bd5671cf07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.1 (2 points)\n",
    "\n",
    "Create a Python function to calculate the RMSE (root mean squared error) for a set of predictions\n",
    "$\\hat{\\mathbf{y}}$:\n",
    "$$\\mathrm{RMSE}(\\mathbf{y},\\hat{\\mathbf{y}}) = \\sqrt{\\frac{\\sum_{i=1}^{m} \\left( y^{(i)}-\\hat{y}^{(i)} \\right)^2}\n",
    "{m}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f72153680f94f124fbed7aa298ebf940",
     "grade": false,
     "grade_id": "cell-15468bfde8ba5a54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1041aa77d319d4e7b5f69f4b0f99dbb",
     "grade": true,
     "grade_id": "cell-e88c1027c162640f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(rmse(np.array([1,1.1,2,-1]), np.array([1.1,1.3,1.5,0.1])))\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.round(rmse(np.array([1,1.1,2,-0.1]), np.array([1.1,1.3,1.5,0.1])), 5) == np.round(0.29154759474226505, 5), \"calculate rmse incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37d116f202758b711de7902124025fe5",
     "grade": false,
     "grade_id": "cell-85f320258dae6cee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output:** 0.6144102863722254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9403b6949e1f6a9200021967b33d00d8",
     "grade": false,
     "grade_id": "cell-8080fbaa538839fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implement a simple linear model\n",
    "\n",
    "OK, as stated earlier, let's implement a simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intercept column of all 1's\n",
    "X_aug = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "# Print first 5 rows of X\n",
    "print(X_aug[0:5,:])\n",
    "\n",
    "# Find optimal parameters\n",
    "theta_slr = regression(X_aug, y)\n",
    "\n",
    "# Predict y\n",
    "y_pred_slr = h(X_aug, theta_slr)\n",
    "\n",
    "print('Linear regression RMSE: %f' % rmse(y, y_pred_slr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "febceb75d4a94b637ee7d6afc3ad18ab",
     "grade": false,
     "grade_id": "cell-57c6d731c3235e74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2 (2 points)\n",
    "\n",
    "From the simple linear model above, create another linear model using a **polynomial** model with degree $d=2$.\n",
    "You need to implement these steps:\n",
    " - Create the design matrix $\\mathtt{X}$ as numpy matrix <code>X_aug</code> similarly to how we set up\n",
    "   <code>X_aug</code> above.\n",
    " - Find the optimal solution $\\theta$ as numpy vector <code>theta_pr</code> similarly to how we set up\n",
    "   <code>theta_slr</code> above.\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint here!</b></font></summary>\n",
    "    \n",
    "Use the <code>np.insert()</code> function to insert a column of $x^2$ values as the last column of <code>X_aug</code>.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de2d9dc7f4abecd0d18fff38e54046b0",
     "grade": false,
     "grade_id": "cell-e4d28679467f4ba5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Add constant column and x^2 column\n",
    "# 2. Find optimal parameters \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deac1e15d28bf8901c014e2cae925014",
     "grade": true,
     "grade_id": "cell-e7b5c28a399a58ae",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict y \n",
    "y_pred_pr = h(X_aug, theta_pr)\n",
    "print(X_aug[0:5,:])\n",
    "print('Polynomial regression RMSE: %f' % rmse(y, y_pred_pr))\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.array_equal(np.round(theta_pr.T), np.round([[1.90932595, 1.02311816, 0.71747835]])), \"theta_pr are incorrect\"\n",
    "assert np.round(X_aug[10,1] ** 2, 5) == np.round(X_aug[10,2], 5), \"X_aug are incorrect\"\n",
    "assert np.round(rmse(y, y_pred_pr) ** 2 * y.shape[0], 5) == np.round(np.dot((y - y_pred_pr).T, y - y_pred_pr), 5), \"RMSE incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c22d1badbcbfbb6a7ab780ba95cc306",
     "grade": false,
     "grade_id": "cell-885e8f4444951e38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output** \\\n",
    "[[ 1.          0.39050803  0.15249652]\\\n",
    " [ 1.          1.72151493  2.96361366]\\\n",
    " [ 1.          0.82210701  0.67585993]\\\n",
    " [ 1.          0.35906546  0.12892801]\\\n",
    " [ 1.         -0.61076161  0.37302974]]\\\n",
    "Polynomial regression RMSE: 0.986690"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32f39214f4fdc511a98ad555a073e134",
     "grade": false,
     "grade_id": "cell-96db0c06cf9f524a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare the two different models using RMSE\n",
    "\n",
    "We see that the degree 2 polynomial fit is much better, reducing average error from 3.4 to 0.99.\n",
    "\n",
    "To further visualize the performance of our model, we should plot the predictions vs. the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c077dc1db06ee3e4e2d1150c8a37f53",
     "grade": false,
     "grade_id": "cell-dd5029e56cbdcc1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.3 (2 points)\n",
    "\n",
    "This one is a bit tricky.\n",
    "\n",
    "We'd like to write a function <code>get_predictions</code> that works for any model\n",
    "degree depending on what $\\theta$ it is passed. The function should take as input\n",
    "a vector of scalar $x$ values along with a set of parameters $\\theta$. It should\n",
    "output a vector of predictions $\\hat{\\mathbf{y}}$.\n",
    "\n",
    "Your <code>get_predictions</code> function needs to construct an appropriate design\n",
    "matrix $\\mathtt{X}$ then use the hypothesis function we already wrote earlier.\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint here!</b></font></summary>\n",
    "\n",
    "1. The code below already converts the input vector <code>x</code> to a 2D $m\\times 1$ matrix.\n",
    "1. Use <code>np.insert</code> to\n",
    "   1. Insert a column of 1's in front of $\\mathbf{x}$\n",
    "   2. Insert a column of $x^2$ values, $x^3$ values, etc., according to the\n",
    "      length of $\\theta$. Use a <code>while</code> loop for this.\n",
    "2. Use <code>h()</code> to get $\\hat{y}$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b0336b811d793c80d400c8d3c8b1b58",
     "grade": false,
     "grade_id": "cell-0e66315d337105dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(x, theta):\n",
    "    # Change the shape of x to support the function\n",
    "    x = np.array([x]).T\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9d67487c494193c55558a27c97d100",
     "grade": true,
     "grade_id": "cell-d0c75741e7ad862c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_series = np.linspace(-4, 4, 1000)\n",
    "y_series_slr = get_predictions(x_series, theta_slr)\n",
    "y_series_pr = get_predictions(x_series, theta_pr)\n",
    "\n",
    "print(\"y_series_slr:\", y_series_slr[2:5].T)\n",
    "print(\"y_series_pr:\", y_series_pr[2:5].T)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.round(get_predictions(np.array([1, 9, 2, -9]), theta_slr).T, 5) is not None, \"predict from theta_slr is incorrect\"\n",
    "assert np.round(get_predictions(np.array([1, 1, 0.1, 2]), theta_pr).T, 5) is not None, \"predict from theta_pr is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a89fc5f62c15108336af45bfcfa41cf",
     "grade": false,
     "grade_id": "cell-9a17566e3350d58f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:\\\n",
    "y_series_slr: [[2.72462183 2.73101513 2.73740842]]\\\n",
    "y_series_pr: [[9.0812643  9.04632656 9.01147497]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c78825b1d8f0d44bcd60e545bbcdab41",
     "grade": false,
     "grade_id": "cell-25ddb38150bdc0d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Plot x against y with the two regression models\n",
    "\n",
    "Now that we have a working <code>get_predictions()</code>, we can\n",
    "plot the data with the linear and quadratic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,0], y, 'c.', label='observations')\n",
    "plt.plot(x_series, y_series_slr, 'b-', label='linear model (d=1)')\n",
    "plt.plot(x_series, y_series_pr, 'r-', label='polynomial model (d=2)')\n",
    "plt.title('Simple linear regression vs. polynomial regression (degree 2)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "440696cad0b5fbf73719ed60a104089f",
     "grade": false,
     "grade_id": "cell-79a834611ae2039f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From the plot, we see clearly that the quadratic model is a much better fit to the data.\n",
    "\n",
    "### Compare models using goodness of fit\n",
    "\n",
    "Besides RMSE, let's also get the $R^2$ for our two models. Recall the formula for $R^2$:\n",
    "\\begin{align}\n",
    "\\ R^2 = 1 - \\frac{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\hat{y}^\\left(i\\right) \\right)^2}\n",
    "{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\bar{y}^\\left(i\\right) \\right)^2}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### Exercise 1.4 (2 points)\n",
    "\n",
    "Fill in the function <code>r_squared()</code> using the equation above.\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint here!</b></font></summary>\n",
    "    Use the <code>np.square()</code> function to square each of the elements of a vector.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b00103a3d4139f5e435bd0c6d5699063",
     "grade": false,
     "grade_id": "cell-337cd120daeea8a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def r_squared(y, y_pred):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return r_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ff121d755532bb3e6078a97154e5a91",
     "grade": true,
     "grade_id": "cell-535c7f9d800ea951",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Fit of simple linear regression model: %.4f' % r_squared(y, y_pred_slr))\n",
    "print('Fit of polynomial regression model: %.4f' % r_squared(y, y_pred_pr))\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.round(r_squared(np.array([1, 2, 3]), np.array([1, 2, 3]))) == np.round(1.0), \"r_squared is incorrect\"\n",
    "assert np.round(r_squared(y, y_pred_pr), 4) == np.round(0.9353, 4), \"r_squared is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0a2758e2817aa5a9718e6e40bc54a73",
     "grade": false,
     "grade_id": "cell-9adf3f8e5bd7a6cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output:**\\\n",
    "Fit of simple linear regression model: 0.2254\\\n",
    "Fit of polynomial regression model: 0.9353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7d888edc0234173b8e2916c4295428e",
     "grade": false,
     "grade_id": "cell-c3bc819623aac6ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "So we see again the superior fit of the quadratic model using $R^2$ (0.94 vs. 0.23).\n",
    "\n",
    "### Compare models using residual histograms\n",
    "\n",
    "Next, let's look at another useful analysis: histograms of each model's residuals. Rather than\n",
    "summarizing the residuals with RMSE or $R^2$, we'll need a function to calculate a vector of\n",
    "residuals. Then we'll be able to make histograms.\n",
    "\n",
    "### Exercise 1.5 (2 points)\n",
    "\n",
    "Fill in function <code>residual_error()</code> to find the residual error vector $\\mathbf{y} - \\hat{\\mathbf{y}}$.\n",
    "\n",
    "Once we have that function, we can calculate <code>error_slr</code> for the simple linear regression\n",
    "and <code>error_pr</code> for the polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02598d56b0806ba96ca3e4ae49c16988",
     "grade": false,
     "grade_id": "cell-d2b59f668e244973",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def residual_error(y, y_pred):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return error\n",
    "\n",
    "error_slr = residual_error(y, y_pred_slr)\n",
    "error_pr = residual_error(y, y_pred_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f99409ffea2d9168188cb0ee8a4098bb",
     "grade": true,
     "grade_id": "cell-b09566ee57735e80",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot distribution of residual error for each model\n",
    "print(\"error_slr sample:\", error_slr[0:5, 0].T)\n",
    "print(\"error_pr sample:\", error_pr[0:5, 0].T)\n",
    "\n",
    "plt.hist(error_slr, bins=10, label = 'Linear')\n",
    "plt.hist(error_pr, bins=10, label = 'Polynomial')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residual error distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.array_equal(np.round(get_predictions(np.array([1, 9, 2, -9]), theta_slr).T),\n",
    "                      np.round([[6.70364883, 13.09055058, 7.50201155, -1.27997835]])), \"predict from theta_slr is incorrect\"\n",
    "assert np.array_equal(np.round(get_predictions(np.array([0, 7, 1.5, -0.3]), theta_pr).T),\n",
    "                      np.round([[2.34050076, 42.14663283, 5.3284002, 2.10566904]])), \"predict from theta_pr is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfb325b196811926ddbcd7a9fd681919",
     "grade": false,
     "grade_id": "cell-6f779a2359b39284",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output:**\\\n",
    "error_slr sample: [-4.88494741 -0.58280848 -2.8007543  -5.27887921 -2.27906541]\\\n",
    "error_pr sample: [-1.49521216  0.67105966  0.15715854 -1.86746535  1.14869785]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9e04f91e501d5dc3b50115a3c6a0a56",
     "grade": false,
     "grade_id": "cell-22d38f90089bbb25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The residual plot again shows clearly how much better the polynomial model is than the linear model.\n",
    "\n",
    "## Example 2: Sales data\n",
    "\n",
    "Next, let's model some real data, in particular,\n",
    "monthly sales data from Kaggle using polynomial regression with varying degree.\n",
    "\n",
    "We will observe the effects of varying the degree of the polynomial regression fit on the prediction accuracy.\n",
    "\n",
    "However, as discussed in class,\n",
    "as models become more complex, we will encounter the issue of *overfitting*, in which a too-powerful\n",
    "model starts to model the noise in the specific training set rather than the overall trend.\n",
    "\n",
    "To ensure that we're not fitting the noise in the training set, we will split the data into seaparte train and test/validation datasets.\n",
    "The training dataset will consist of 60% of the original observations, and the test dataset will consist of the remaining 40% of the observations.\n",
    "\n",
    "For various polynomial degrees, we'll estimate optimal parameters $\\theta$, from the\n",
    "training set, then we'll use the test/validation dataset to measure the accuracy of the optimized model.\n",
    "\n",
    "First, let's read the data from the CSV file and set up variables <code>X_data</code>, <code>y_data</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV\n",
    "data = np.genfromtxt('MonthlySales_data.csv',delimiter = ',', dtype=str)\n",
    "\n",
    "# Extract headers\n",
    "headers = data[0,:]\n",
    "print(\"Headers:\", headers)\n",
    "\n",
    "# Extract raw data\n",
    "data = np.array(data[1:,:], dtype=float);\n",
    "mean = np.mean(data,axis=0)\n",
    "std = np.std(data,axis=0)\n",
    "data_norm = (data-mean)/std\n",
    "\n",
    "# Extract y column from raw data\n",
    "y_index = np.where(headers == 'sale amount')[0][0];\n",
    "y_data = data[:,y_index];\n",
    "\n",
    "# Extract x column (just the month) from raw data\n",
    "month_index = np.where(headers == 'month')[0][0]\n",
    "# print(year_index, month_index)\n",
    "X_data = data[:,[month_index]];\n",
    "m = X_data.shape[0]\n",
    "n = X_data.shape[1]\n",
    "X_data = X_data.reshape(m, n)\n",
    "\n",
    "print('Extracted %d monthly sales records' % m)\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94516825649a6e66154652c1c4a3ce81",
     "grade": false,
     "grade_id": "cell-90337e4eafe3ac8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Plot the data\n",
    "\n",
    "Although year and month are discrete variables, they are also ordinal, so they can be\n",
    "treated as real values. Let's plot sales month against sales amount as a scatter plot, and\n",
    "we'll see the discrete nature of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "xx1 = X_data[:,0]\n",
    "yy1 = y_data\n",
    "\n",
    "plt.plot(xx1, yy1, 'b.')\n",
    "plt.xlim(0, 13)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales amount')\n",
    "plt.title('Sample monthly sales data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4d177b7fce3ed069b79cb1bff2aea1c",
     "grade": false,
     "grade_id": "cell-b363fa8e24421d63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Partition the data\n",
    "\n",
    "Next let's split the overall dataset into subsets for training and validation (test).\n",
    "\n",
    "### Exercise 1.6 (2 points)\n",
    "\n",
    "Partition <code>X_data</code> and <code>y_data</code> into training and test datasets\n",
    " - Let the training set be 60% of the dataset\n",
    " - Let the rest be the test set\n",
    " - Shuffle the dataset before splitting it to ensure a similar distribution in the two subsets\n",
    " \n",
    "You can use the [<code>random.shuffle()</code> function](https://www.w3schools.com/python/ref_random_shuffle.asp)</link> to shuffle the indices of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7701033e548e05e2caabc8e70034e0b",
     "grade": false,
     "grade_id": "cell-b7bb05a7472dbde0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "percent_train = .6\n",
    "\n",
    "def partition(X, y, percent_train):\n",
    "    # Create a list of indices into X and y\n",
    "    idx = np.arange(0,y.shape[0])\n",
    "    random.seed(1412)   # just make sure the shuffle always the same please do not remove\n",
    "    # On your own, do the following:\n",
    "    # 1. shuffle the idx list\n",
    "    # 2. Create lists of indices train_idx and test_idx for the train and test sets\n",
    "    # 3. Set variables X_train, y_train, X_test, and y_test using those index lists\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return idx, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5892ca109bbe0ee9d7718a20e71e2489",
     "grade": true,
     "grade_id": "cell-da342893c5f9083b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "idx, X_train, y_train, X_test, y_test = partition(X_data, y_data, percent_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(idx[5:9])\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert not np.array_equal(np.round(X_data[0:144, :], 3), np.round(X_train,3)), \"X_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(X_data[144:, :], 3), np.round(X_test,3)), \"X_test must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_data[0:144], 3), np.round(y_train,3)), \"y_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_data[144:], 3), np.round(y_test,3)), \"y_test must be shuffled!\"\n",
    "assert np.array_equal(idx[5:9], [26, 75, 51, 162])\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc6a1b0835e06dd3485ec3b6e85f7e8b",
     "grade": false,
     "grade_id": "cell-5a69ef7f6637a7e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output:**\\\n",
    "(144, 1)\\\n",
    "(144,)\\\n",
    "(96, 1)\\\n",
    "(96,)\\\n",
    "[ 26  75  51 162]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fef5968c2be4b951ddb5a3420bba967",
     "grade": false,
     "grade_id": "cell-8e669b7c16801a41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Set up for polynomial regression\n",
    "\n",
    "Next, let's implement the transformation of a variable $x$ into the\n",
    "expanded list $\\begin{bmatrix} x & x^2 & \\cdots & x^d \\end{bmatrix}$.\n",
    "\n",
    "### Exercise 1.7 (2 points)\n",
    "\n",
    "Fill in function <code>x_polynomial()</code> with code to output\n",
    "a row vector consisting of the elements $x, x^2, \\ldots, x^d$, where\n",
    "when $d$ is the degree of the polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1e2ef4726dfe4fa99f284f6152e7837",
     "grade": false,
     "grade_id": "cell-76860eaedb1e088b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def x_polynomial(x, d):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2211d80f3f0f85cf1962b6706796b97",
     "grade": true,
     "grade_id": "cell-44f06f0709d85512",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(x_polynomial(np.array([[3],[2]]), 5))\n",
    "print(x_polynomial(np.array([[3],[2]]), 5).shape)\n",
    "\n",
    "Xi_train = x_polynomial(X_train, 1)    \n",
    "Xi_test = x_polynomial(X_test, 1)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert x_polynomial(np.array([[2],[3]]), 5).shape[1] == 5 + 1, \"Size of polynomial incorrect\"\n",
    "assert np.array_equal(np.round(x_polynomial(np.array([[2],[3]]), 5), 3), \n",
    "                      np.round([[1, 2, 4, 8, 16, 32], [1, 3, 9, 27, 81, 243]],3)), \"Polynomial are wrong.\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a08008c99035bcbb70a1efe3427c48d",
     "grade": false,
     "grade_id": "cell-9e0e92ebf2cc6b90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output:**\\\n",
    "[[  1.   3.   9.  27.  81. 243.]\\\n",
    " [  1.   2.   4.   8.  16.  32.]]\\\n",
    "(2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "268c87445f76a7ad6f77a5040391372d",
     "grade": false,
     "grade_id": "cell-2e817d9ad008f192",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Write the cost function\n",
    "\n",
    "Next let's implmeent to cost function for a given set of parameters $\\theta$.\n",
    "\n",
    "### Exercise 1.8 (2 points)\n",
    "\n",
    "Fill in function <code>cost()</code> with appropriate code. Use a constant of $\\frac{1}{2m}$ out front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d95abc217d619465491314171135e3ac",
     "grade": false,
     "grade_id": "cell-c0a1095e6a66f70e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fdcc2543e68cd584c7ff70d46fe8132",
     "grade": true,
     "grade_id": "cell-e7b476298e7765e4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate theta\n",
    "theta = regression(Xi_train, y_train)\n",
    "\n",
    "# calculate cost in train\n",
    "J_train = cost(theta, Xi_train, y_train)\n",
    "\n",
    "y_pred_test = h(Xi_test, theta)\n",
    "J_test = cost(theta, Xi_test, y_test)\n",
    "\n",
    "print(\"J_train:\", J_train)\n",
    "print(\"J_test:\", J_test)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert type(J_train) == np.float64, \"Cost function size must be 1\"\n",
    "assert np.round(J_train, 3) == np.round(174395635.44334993, 3), \"Cost function for train set is wrong\"\n",
    "assert np.round(J_test, 3) == np.round(196382485.91395777, 3), \"Cost function for test set is wrong\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "395fadce0a6ec7c0ff75437265a3d5bf",
     "grade": false,
     "grade_id": "cell-49f1948f892e79dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output:**\\\n",
    "J_train: 174395635.44334993\\\n",
    "J_test: 196382485.91395777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d17e692afb5442cb6441ab62b7d8540",
     "grade": false,
     "grade_id": "cell-8e7c6c03b74d9a41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Try models of varying degree\n",
    "\n",
    "Next we'll build multiple polynomial regression models with different degree, using sales\n",
    "month as the independent variable and sales amount as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 5\n",
    "\n",
    "J_train = np.zeros(max_degree)\n",
    "J_test = np.zeros(max_degree)\n",
    "\n",
    "# Initalize plots for predictions and loss\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(20)\n",
    "fig.subplots_adjust(left=.2, bottom=None, right=None, top=None, wspace=.2, hspace=.2)\n",
    "plt1 = plt.subplot(1,2,1)\n",
    "plt2 = plt.subplot(1,2,2)\n",
    "plt2.plot(X_train, y_train, 'c.', label='observations')\n",
    "\n",
    "for i in range(1, max_degree+1):\n",
    "    # Fit model on training data and get cost for training and test data\n",
    "    Xi_train = x_polynomial(X_train, i)    \n",
    "    Xi_test = x_polynomial(X_test, i);\n",
    "    theta = regression(Xi_train, y_train)    \n",
    "    J_train[i-1] = cost(theta, Xi_train, y_train)\n",
    "    y_pred_test = h(Xi_test, theta)\n",
    "    J_test[i-1] = cost(theta, Xi_test, y_test)\n",
    "    \n",
    "    # Plot\n",
    "    x_series = np.linspace(0, 13, 1000)\n",
    "    y_series = get_predictions(x_series, theta)\n",
    "    plt2.plot(x_series, y_series, '-', label='degree ' + str(i) + ' (test accuracy ' + str(r_squared(y_test, y_pred_test)) + ')')\n",
    "\n",
    "plt1.plot(np.arange(1, max_degree + 1, 1), J_train, '-', label='train')\n",
    "plt1.plot(np.arange(1, max_degree + 1, 1), J_test, '-', label='test')\n",
    "plt1.set_title('Loss vs polynomial degree')\n",
    "plt1.set_xlabel('polynomial degree')\n",
    "plt1.set_ylabel('loss')\n",
    "plt1.grid(axis='both', alpha=.25)\n",
    "plt1.legend()\n",
    "\n",
    "plt2.set_title('Predicted monthly sales')\n",
    "plt2.set_xlabel('Month')\n",
    "plt2.set_ylabel('Sales ($)')\n",
    "plt2.grid(axis='both', alpha=.25)\n",
    "plt2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb5943bd9f4bfdafb1b9c4769c687cf9",
     "grade": false,
     "grade_id": "cell-62fb80f9a7f852e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take some time to undserstand the code. You should see that training loss falls as the degree of the polynomial increases. However, depending on your particular train/test split of the data, you may observe at $d=4$ or $d=5$ that test loss starts to flatten out or even increase. This is the phenomenon of overfitting!\n",
    "\n",
    "If you don't see any evidence of overfitting, you might regenerate the test/train splits (comment out the seed\n",
    "setting in the partition function and re-run the rest of the cells, but don't forget to put the seed back before\n",
    "turning in your solution!).\n",
    "\n",
    "You may also increase max_degree to a point. However, without normalization of the data, the matrix $\\texttt{X}^\\top\\texttt{X}$ we invert in the solution to the normal equations will become numerically close to singularity, and you will observe unstable solutions. The result is usually a parameter vector $\\theta$ that is suboptimal that gives poor results on both the training set and test set.\n",
    "\n",
    "If you want to evaluate the numerial stability of the correlation matrix $\\texttt{X}^\\top\\texttt{X}$, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = Xi_train.T.dot(Xi_train)\n",
    "print('Correlation matrix:', corr)\n",
    "cond = np.linalg.cond(corr)\n",
    "print('Condition number: %0.5g' % cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fa51705a957ad76c5742a1b443e8457",
     "grade": false,
     "grade_id": "cell-73b01dfe3d80c217",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Read more about the condition number on <link>[Wikipedia](https://en.wikipedia.org/wiki/Condition_number)</link>. Roughly speaking, if our condition number is $10^k$, we may lose up to $k$ digits of accuracy in the inverse of the matrix. If $k=12$ as above, then we have an extremely poorly conditioned problem, because the IEEE 64 bit floating point representation of reals we're using in Python only has around 16 digits of accuracy (see <link>[Wikipedia's page on IEEE floating point numbers](https://en.wikipedia.org/wiki/IEEE_754)</link>).\n",
    "\n",
    "One way to improve the numerical conditioning of the problem is normalization. If the values of the variables we\n",
    "are correlating in this matrix have relatively small positive and negative values, the condition number of the correlation matrix will be much smaller and you'll get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d39ae61cfddcceeed43eff703695d90",
     "grade": false,
     "grade_id": "cell-dd696834fab67203",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## In-lab exercises\n",
    "\n",
    "During the lab session, you should perform the following exercises:\n",
    "1. Add the `year` variable from the monthly sales dataset to your simple linear regression model and quantify\n",
    "   whether including it improves test set performance. Show\n",
    "   the observations and predictions in a 3D surface plot.\n",
    "2. Develop polynomial regression models of degree 2 and 3 based on the two input variables. Show results\n",
    "   as 3D surface plots and discuss whether you observe overfitting\n",
    "   or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24b376b9d86d548f37effbafee308a1d",
     "grade": false,
     "grade_id": "cell-cea5de1c2bd78b4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "### Exercise 2.1 (2 points)\n",
    "\n",
    "Import **MonthlySales_data.csv** file into <code>data_csv</code> and extract **headers**  at the top of <code>data_csv</code> into <code>headers_csv</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfd7a3d46ea6f966a4222bc8a4fc3727",
     "grade": false,
     "grade_id": "cell-b43030a1c52e7d4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87766378de780066194a97a6ee5e9ab7",
     "grade": true,
     "grade_id": "cell-53eecb55f9059986",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(headers_csv)\n",
    "print(data_csv[:5])\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert type(data_csv[0,0]) == np.float64, \"You must remove the header\"\n",
    "assert headers_csv.shape[0] == 3, \"Headers must have 3 values\"\n",
    "assert type(headers_csv[0]) == np.str_, \"Headers must be string\"\n",
    "assert np.round(data_csv[30, 2], 3) == np.round(2.222027e+04, 3), \"Data is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0585665d0ac33dc762dfa88f625aa757",
     "grade": false,
     "grade_id": "cell-9e0e92ebf2cc6b91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:\\\n",
    "['year' 'month' 'sale amount']\\\n",
    "[[1.995000e+03 1.000000e+00 1.238611e+04]\\\n",
    " [1.995000e+03 2.000000e+00 1.532923e+04]\\\n",
    " [1.995000e+03 3.000000e+00 5.800217e+04]\\\n",
    " [1.995000e+03 4.000000e+00 5.130520e+04]\\\n",
    " [1.995000e+03 5.000000e+00 1.645247e+04]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3499b5a88a3dbc2fb6f35b3553d9a9f",
     "grade": false,
     "grade_id": "cell-798a4324eb8f33f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.2 (2 points)\n",
    "\n",
    "- Extract **sale amount** column into <code>y_csv</code>\n",
    "- Extract **year** and **month** columns into <code>X_csv</code> by use **year** at column index 0 and **month** at column index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc13a6d2460fc1068225f01b9150f0f5",
     "grade": false,
     "grade_id": "cell-0e0c8afd2aa3bdd2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract y column from raw data\n",
    "# Extract x column (year and month) from raw data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91bc14ea7488db7e0bf7e0352adf8b04",
     "grade": true,
     "grade_id": "cell-a15bf28e79e3ff7c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m = X_csv.shape[0]\n",
    "n = X_csv.shape[1]\n",
    "X_csv = X_csv.reshape(m, n)\n",
    "print('Extracted %d sales records' % m)\n",
    "print('number of x set:', n)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert m == 240, \"Sales records incorrect\"\n",
    "assert n == 2, \"Need to extract 2 columns of X set\"\n",
    "assert np.max(X_csv[:,0]) == 2014 and np.min(X_csv[:,0]) == 1995, \"Year is filled wrong column\"\n",
    "assert np.max(X_csv[:,1]) == 12 and np.min(X_csv[:,1]) == 1, \"Month is filled wrong column \"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fad2469a80c1f6b41b90f0e89e12b7ba",
     "grade": false,
     "grade_id": "cell-e55d4553a54422ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:\\\n",
    "Extracted 240 sales records\\\n",
    "number of x set: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca429b94832a3d51f647bd2fcd6f60d5",
     "grade": false,
     "grade_id": "cell-8a6a8d267c5be8a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.3 (2 points)\n",
    "\n",
    "Plot a 3D graph using the <code>mpl_toolkits.mplot3d</code> library.\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint here!</b></font></summary>\n",
    "    Refer to the [matplotlib documentation page](https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html)\n",
    "    for an example.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6010c3490c547eb61e31fbd6088e504b",
     "grade": false,
     "grade_id": "cell-396d4f92e0a00a7f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "# 1. Set plot graph as 3D\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# 2. Extract data\n",
    "# extract year at x-axis\n",
    "# extract month at y-axis\n",
    "# extract sale amount at z-axis\n",
    "x_year = None\n",
    "y_month = None\n",
    "z_sale = None\n",
    "\n",
    "# 3. plot by using scatter\n",
    "\n",
    "# 4. set x, y, z label\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e27203d86ffc1bcee8f71d64e4c78a8",
     "grade": true,
     "grade_id": "cell-7b0eaf5026faac6e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test function: Do not remove\n",
    "assert ax.get_xbound()[1] >= 2014 and ax.get_xbound()[0] <= 1995, \"Year is filled wrong column\"\n",
    "assert ax.get_ybound()[1] >= 12 and ax.get_ybound()[0] <= 1, \"Month is filled wrong column\"\n",
    "assert ax.get_zbound()[1] >= 100000 and ax.get_zbound()[0] <= 0, \"Year is filled wrong column\"\n",
    "assert 'year' in ax.get_xlabel().lower(), \"x-axis label is incorrect\"\n",
    "assert 'month' in ax.get_ylabel().lower(), \"y-axis label is incorrect\"\n",
    "assert 'sale' in ax.get_zlabel().lower(), \"y-axis label is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f04c2aef480ae1b43d33ad159535035a",
     "grade": false,
     "grade_id": "cell-5966226c4878c809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output:**\\\n",
    "<img src=\"lab02-01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f579f1854eff19ee77cef98cd25399d",
     "grade": false,
     "grade_id": "cell-7228b4a546408255",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.4 (2 points)\n",
    "\n",
    "Extract 60% of the data to the training set and the remaining 40% to the test set with shuffling.\n",
    "\n",
    "You can use the <code>partitions</code> function we already made or create a new function. Make sure\n",
    "that you use <code>random.seed(1412)</code> to make sure that the result is the same as the expect result.\n",
    "Place the resulting data in variables <code>idx, X_train, y_train, X_test, y_test</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39cc4725f5edf710eeed230c812907e3",
     "grade": false,
     "grade_id": "cell-146749df078ffcfd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "idx, X_train, y_train, X_test, y_test = None, None, None, None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfda602ea828db2faa7afce5b470b84f",
     "grade": true,
     "grade_id": "cell-e18853d209ee0afe",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(idx[5:9])\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert not np.array_equal(np.round(X_csv[0:144, :], 3), np.round(X_train,3)), \"X_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(X_csv[144:, :], 3), np.round(X_test,3)), \"X_test must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_csv[0:144], 3), np.round(y_train,3)), \"y_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_csv[144:], 3), np.round(y_test,3)), \"y_test must be shuffled!\"\n",
    "assert np.array_equal(idx[5:9], [26, 75, 51, 162])\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6eedd32cd59fc2d081756a95ab483855",
     "grade": false,
     "grade_id": "cell-c5118f9d1f51fda2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:\\\n",
    "(144, 2)\\\n",
    "(144,)\\\n",
    "(96, 2)\\\n",
    "(96,)\\\n",
    "[ 26  75  51 162]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4da0d502078c73721803a760572df6b2",
     "grade": false,
     "grade_id": "cell-371ebc7eb2864a6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.5 (2 points)\n",
    "\n",
    "1. Create <code>Xi_train, Xi_Test</code>. X sets must be polynomial of $n=1$.\n",
    "2. Calculate <code>theta</code>\n",
    "2. Calculate <code>y_pred_test</code>\n",
    "2. Calculate cost function $J$ from train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d82afff1c1da3c97e67a83809d93e8d",
     "grade": false,
     "grade_id": "cell-43c618dd04ceb9c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Xi_train, Xi_test = None, None\n",
    "theta = None\n",
    "y_pred_test = None\n",
    "J_train, J_test = None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf9d8dce7dd9fd801f36a6ff6b40cb82",
     "grade": true,
     "grade_id": "cell-ebaba3da531f0ef0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Xi_train[:3]:\", np.round(Xi_train[:3], 2))\n",
    "print(\"Xi_test[:3]:\", np.round(Xi_test[:3], 2))\n",
    "print(\"theta:\", theta)\n",
    "print(\"y_pred_test[:5]:\", np.round(y_pred_test[:5].T, 2))\n",
    "print(\"J_train:\", J_train)\n",
    "print(\"J_test:\", J_test)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.array_equal(np.round(theta, 3), np.round([5.74503812e+05, -2.83158807e+02, 6.37579347e+03],3)), \"Regression theta is incorrect\"\n",
    "assert np.round(J_train, 0) == np.round(172968387.44854635, 0), \"Train cost is incorrect\"\n",
    "assert np.round(J_test, 0) == np.round(204275431.7643744, 0), \"Test cost is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "431b128b7bff3d0f7acbca436f086bdc",
     "grade": false,
     "grade_id": "cell-c710a1b999488f97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:\\\n",
    "Xi_train[:3]: [[1.000e+00 2.003e+03 1.100e+01]\\\n",
    " [1.000e+00 2.004e+03 3.000e+00]\\\n",
    " [1.000e+00 2.002e+03 6.000e+00]]\\\n",
    "Xi_test[:3]: [[1.000e+00 2.008e+03 1.000e+01]\\\n",
    " [1.000e+00 1.997e+03 5.000e+00]\\\n",
    " [1.000e+00 2.006e+03 1.100e+01]]\\\n",
    "theta: [5.74503812e+05 -2.83158807e+02  6.37579347e+03]\\\n",
    "y_pred_test[:5]: [69678.86 40914.64 76620.97 79169.4  48852.53]\\\n",
    "J_train: 172968387.44854635\\\n",
    "J_test: 204275431.7643744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5eccc0b0a580109d35371f4c0b0d2ed",
     "grade": false,
     "grade_id": "cell-7ea805d8d46203af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.6 (2 points)\n",
    "\n",
    "Create a mesh of grid points in order to obtain a surface plot later.\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint here!</b></font></summary>\n",
    "    Create a mesh grid using [<code>numpy.meshgrid()</code>](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47b3a6ee7954a04286e29982d96e29a5",
     "grade": false,
     "grade_id": "cell-1d73b15f2ebd57a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create mesh grid x_mesh, y_mesh\n",
    "#    Hint: this step do in input X dataset only (year, and month series)\n",
    "# 1.1 use numpy.linspace() to generate x_series and y_series\n",
    "#     - do x_series in between min(year) - 1 to max(year) + 1\n",
    "#     - do y_series in between min(month) - 1 to max(month) + 1\n",
    "#     - num_linspace = 100\n",
    "# 1.2 use numpy.meshgrid() to generate x_mesh, and y_mesh\n",
    "# 1.3 merge x_mesh and y_mesh to be xy_mesh\n",
    "num_linspace = 100\n",
    "x_series, y_series = None, None\n",
    "x_mesh, y_mesh, xy_mesh = None, None, None\n",
    "\n",
    "# 2. predict output from xy_mesh to be z_series\n",
    "#    Hint: use mesh_predictions function instead of get_prediction\n",
    "def mesh_predictions(x, theta):\n",
    "    x = np.insert(x, 0, 1, axis=x.ndim-1)\n",
    "    theta = theta.reshape(-1,1)\n",
    "    y = x@theta\n",
    "    return y\n",
    "z_series = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a7dd306e8d61b2555f3a9bc6d0df2a8",
     "grade": true,
     "grade_id": "cell-9a816cae85d439af",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"xy_mesh.shape\", xy_mesh.shape)\n",
    "print(\"z_series.shape\", z_series.shape)\n",
    "#print(\"xy_mesh\", xy_mesh)\n",
    "#print(\"z_series\", z_series)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert xy_mesh.shape == (num_linspace, num_linspace, 2), \"mesh shape is incorrect\"\n",
    "assert z_series.shape == (num_linspace, num_linspace), \"z_series is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd75e91abf6e27cce567d057c515c298",
     "grade": false,
     "grade_id": "cell-505cf4272cde5a84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:\\\n",
    "xy_mesh.shape (100, 100, 2)\\\n",
    "z_series.shape (100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d8ef5f2ef3a62ca7f13d7d6e355f655",
     "grade": false,
     "grade_id": "cell-ab8bef4203ed281f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "### Exercise 2.6 (2 points)\n",
    "\n",
    "Make a surface plot for theta with the dataset points from <code>xy_mesh</code> and <code>z_series</code>\n",
    "variables created above.\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint here!</b></font></summary>\n",
    "    You can use the [<code>Axes3D.plot_surface()</code> function](https://matplotlib.org/2.0.2/mpl_toolkits/mplot3d/tutorial.html).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c13d6871744630c15ec9ffd8214f646",
     "grade": false,
     "grade_id": "cell-0473984307b36986",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "# 1. Set plot graph as 3D\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# 2. Extract data\n",
    "# extract year at x-axis\n",
    "# extract month at y-axis\n",
    "# extract sale amount at z-axis\n",
    "x_year = None\n",
    "y_month = None\n",
    "z_sale = None\n",
    "\n",
    "# 3. plot by using scatter\n",
    "# 4. set x, y, z label\n",
    "#    Hint: In these 3, 4 steps, you can copy Exercise 2.3\n",
    "# 5. Plot surface from x_mesh, y_mesh, and z_series\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c9cedd71cde961389e4539aa31a62cb",
     "grade": true,
     "grade_id": "cell-d89f019001f81ea1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test function: Do not remove\n",
    "assert ax.get_xbound()[1] >= 2014 and ax.get_xbound()[0] <= 1995, \"Year is filled wrong column\"\n",
    "assert ax.get_ybound()[1] >= 12 and ax.get_ybound()[0] <= 1, \"Month is filled wrong column\"\n",
    "assert ax.get_zbound()[1] >= 100000 and ax.get_zbound()[0] <= 0, \"Year is filled wrong column\"\n",
    "assert 'year' in ax.get_xlabel().lower(), \"x-axis label is incorrect\"\n",
    "assert 'month' in ax.get_ylabel().lower(), \"y-axis label is incorrect\"\n",
    "assert 'sale' in ax.get_zlabel().lower(), \"y-axis label is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2e6d8ba27c032409bed6480dae3aa84",
     "grade": false,
     "grade_id": "cell-ec03204b2cc9283a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result:**\n",
    "<img src=\"lab02-02.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d0abe75cd7d89f7998fb9b72dda2a90",
     "grade": false,
     "grade_id": "cell-1cff05f8209faa18",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 2.7 (20 points)\n",
    "\n",
    "Develop polynomial regression models of degree 2 and 3 based on the two input variables. Show results as 3D surface plots and discuss whether you observe overfitting or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd2929356d80c642e4ec5437abc8658a",
     "grade": false,
     "grade_id": "cell-e7b8b113e71378d9",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Take-home exercise (50 points)\n",
    "\n",
    "Using the dataset you played with for the take-home exercise in Lab 01, perform the same analysis. You won't be able to visualize the model well, as you will have more\n",
    "than two inputs, but try to give some idea of the performance of the model visually. Also, depending on the number of variables in your dataset, you may not be able to\n",
    "increase the polynomial degree beyond 2. Discuss whether the polynomial model is better than the linear model and whether you observe overfitting.\n",
    "\n",
    "Insert your code, explanation, and results here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To turn in\n",
    "\n",
    "Before the next lab, turn in a brief report in the form of a Jupyter notebook documenting your work in the lab and the take-home exercise, along with your observations and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
