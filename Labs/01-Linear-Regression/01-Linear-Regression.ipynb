{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: After modify code, you must remove <code>raise NotImplementedError()</code> from your answer cell, unless the cell will have error occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fec63a9ab2900bec01865d074dd91e1",
     "grade": false,
     "grade_id": "cell-59e6313957d4919c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 01-Linear Regression\n",
    "\n",
    "In this lab, we'll take a look at how to build and evaluate linear regression models. Linear regression works well when there is an (approximately) linear relationship between the features and the variable we're trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's import the Python packages we'll need for the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d028e30de4d05425c33009198982dff",
     "grade": false,
     "grade_id": "cell-1c10d796359f5ff9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Univariate example\n",
    "Here's an example from <code>[Tim Niven's tutorial at Kaggle](https://www.kaggle.com/timniven/linear-regression-tutorial)</code>.\n",
    "\n",
    "### Background\n",
    "We would like to perform *univariate* linear regression using a single feature $x$, \"Number of hours studied,\" to predict a single dependent variable, $y$, \"Exam score.\"\n",
    "\n",
    "We can say that we want to regress <code>num_hours_studied</code> onto <code>exam_score</code> in order to obtain a model to predict a student's exam score using the number of hours he or she studied.\n",
    "\n",
    "In the standard setting, we assume that the dependent variable (the exam score) is a random variable that has a Gaussian distribution whose mean is a linear function of the independent variable(s) (the number of hours studied) and whose variance is unknown but constant:\n",
    "\n",
    "\\begin{equation}\n",
    "y\\sim\\mathcal{N}(\\theta_0+\\theta_1x,\\sigma^2)\n",
    "\\end{equation}\n",
    "\n",
    "Our model or hypothesis, then, will be a function predicting $y$ based on $x$:\n",
    "\\begin{equation}\n",
    "h_\\theta(x)=\\theta_0+\\theta_1x\n",
    "\\end{equation}\n",
    "\n",
    "Next we'll do something very typical in machine learning experiment: generate some synthetic data for which we know the \"correct\" model, then use those data to test our algorithm for finding the best model.\n",
    "\n",
    "So let's generate some example data and examine the relationship between $x$ and $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variable\n",
    "num_hours_studied = np.array([1, 3, 3, 4, 5, 6, 7, 7, 8, 8, 10])\n",
    "\n",
    "# Dependent variable\n",
    "exam_score = np.array([18, 26, 31, 40, 55, 62, 71, 70, 75, 85, 97])\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(num_hours_studied, exam_score)\n",
    "plt.xlabel('num_hours_studied')\n",
    "plt.ylabel('exam_score')\n",
    "plt.title('Synthetic Exam Score Data Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading data from file, we can use numpy to load into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txt = np.loadtxt('lab1data1.txt', delimiter=',', usecols=(0, 1))\n",
    "print(data_txt.shape)\n",
    "\n",
    "plt.scatter(data_txt[:,0], data_txt[:,1])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('data 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f570d8a01ac757ab2026c6ba50eb84e9",
     "grade": false,
     "grade_id": "cell-8b0260aa73a1656f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Design Matrix\n",
    "The design matrix, usually written $\\mathtt{X}$, contains our independent variables.\n",
    "\n",
    "In general, with $m$ data points and $n$ features (independent variables), our design matrix will have $m$ rows and $n$ columns.\n",
    "\n",
    "Note that we have a parameter $\\theta_0$, which is the $y$-intercept term in our linear model. There is no independent variable to multiple $\\theta_0$, so we will introduced a dummy variable always equal to 1 to represent the independent variable corresponding to $\\theta_0$.\n",
    "\n",
    "Putting the dummy variable and the number of hours studied together, we obtain the design matrix\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathtt{X} = \\begin{bmatrix}\n",
    "    1 & 1\\\\\n",
    "    1 & 3\\\\\n",
    "    1 & 3\\\\\n",
    "    1 & 4\\\\\n",
    "    1 & 5\\\\\n",
    "    1 & 6\\\\\n",
    "    1 & 7\\\\\n",
    "    1 & 7\\\\\n",
    "    1 & 8\\\\\n",
    "    1 & 8\\\\\n",
    "    1 & 10\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation} \\\n",
    "Notice that we do **not** include the dependent variable (exam score) in the design matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94d33e99d457b22de55c1d26a369521d",
     "grade": false,
     "grade_id": "cell-7ba30352f2253fce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Add dummy variable for intercept term to design matrix.\n",
    "\n",
    "To understand the numpy insert function, reading from this [link](https://numpy.org/doc/stable/reference/generated/numpy.insert.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert num_hours_studied to be 2D array\n",
    "X = np.array([num_hours_studied]).T\n",
    "# Add '1' in front of ordinary data\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "# set exam_score into y\n",
    "y = exam_score\n",
    "# print out the shape of X and y to make sure this is correct dimention\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d85ad8a846b1265a922c352b7e07604c",
     "grade": false,
     "grade_id": "cell-9cb381ea0ae0340e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.1 (2 point)\n",
    "\n",
    "Extract <code>data_txt</code> from *lab1data1.txt* file to be X_data, and y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f578981eea80eb0fdf7eb81e683f02c",
     "grade": false,
     "grade_id": "cell-0a1f23f90d1d01d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_data = None\n",
    "y_data = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d76e2ed071931b443bb972e7b077e5ac",
     "grade": true,
     "grade_id": "cell-303c082e4504a4be",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "assert X_data.shape == (97,2), \"Data size in X1 is incorrect\"\n",
    "assert y_data.shape == (97,), \"Data size in y1 is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expect output**: \\\n",
    "(97, 2) \\\n",
    "(97,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54d3b76878d8a5929a1e7cd09e38069c",
     "grade": false,
     "grade_id": "cell-d79875dbfd64ada5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "Let's rewrite the hypothesis function now that we have a dummy variable for the intercept term in the model. We can write the independent variables including the dummy variable as a vector\n",
    "\n",
    "$$\\mathbf{x} = \\begin{bmatrix} x_0 \\\\ x_1 \\end{bmatrix}, $$\n",
    "\n",
    "where $x_0 = 1$ is our dummy variable and $x_1$ is the number of hours studied. We also write the parameters as a vector\n",
    "\n",
    "$$\\mathbf{\\theta} = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\end{bmatrix} .$$\n",
    "\n",
    "Now we can conveniently write the hypothesis as\n",
    "\n",
    "$$ h_\\mathbf{\\theta}(\\mathbf{x}) = \\mathbf{\\theta}^\\top \\mathbf{x} . $$\n",
    "\n",
    "## Exercise 1.2 (2 point)\n",
    "\n",
    "Write a Python code function to evaluate a hypothesis $\\mathbf{\\theta}$ for an entire design matrix:\n",
    "\n",
    "**Hint**: Use numpy function of <code>dot</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d6ffe67108799cf1f3142a6095d5683",
     "grade": false,
     "grade_id": "cell-997f03f005fa2365",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate hypothesis over a design matrix\n",
    "\n",
    "def h(X,theta):\n",
    "    y_predicted = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b4bd52251acb0cbeaed9bf64dd10375",
     "grade": true,
     "grade_id": "cell-492acb5bb189c7b4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_test = np.array([0, 10])\n",
    "res = h(X, theta_test)\n",
    "res2 = h(X_data, theta_test)\n",
    "\n",
    "print(\"result1\", res)\n",
    "print(\"result2\", res2)\n",
    "assert res.shape[0] == 11 or res.shape == 11, \"Data size in result is incorrect\"\n",
    "assert res[4] == 50, \"Data result is incorrect\"\n",
    "assert res2.shape[0] == 97 or res2.shape == 97, \"Data size in result2 is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "558da40d7fcab0ce8f8fc97689a847e3",
     "grade": false,
     "grade_id": "cell-4df2b703a631f363",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**: \\\n",
    "result1 [ 10  30  30  40  50  60  70  70  80  80 100] \\\n",
    "result2 [ 61.101  55.277  85.186  70.032  58.598  83.829  74.764  85.781  64.862\n",
    "  50.546  57.107 141.64   57.34   84.084  56.407  53.794  63.654  51.301\n",
    "  64.296  70.708  61.891 202.7    54.901  63.261  55.649 189.45  128.28\n",
    " 109.57  131.76  222.03   52.524  65.894  92.482  58.918  82.111  79.334\n",
    "  80.959  56.063 128.36   63.534  54.069  68.825 117.08   57.737  78.247\n",
    "  70.931  50.702  58.014 117.     55.416  75.402  53.077  74.239  76.031\n",
    "  63.328  63.589  62.742  56.397  93.102  94.536  88.254  51.793 212.79\n",
    " 149.08  189.59   72.182  82.951 102.36   54.994 203.41  101.36   73.345\n",
    "  60.062  72.259  50.269  65.479  75.386  50.365 102.74   51.077  57.292\n",
    "  51.884  63.557  97.687  65.159  85.172  91.802  60.02   55.204  50.594\n",
    "  57.077  76.366  58.707  53.054  82.934 133.94   54.369]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc3768bc596c09f7ca40c9b40187c853",
     "grade": false,
     "grade_id": "cell-f0dbe51b109b574b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Cost function\n",
    "How can we find the best value of $\\mathbf{\\theta}$? We need a cost function and an algorithm to minimize that cost function.\n",
    "\n",
    "In a regression problem, we normally use squared error to measure the goodness of fit:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\ J(\\mathbf{\\theta}) & = \\frac{1}{2} \\sum_{i=1}^{m}\\left(h_\\mathbf{\\theta}\\left(\\mathbf{x}^{(i)}\\right) - y^{(i)}\\right)^2 \\\\\n",
    "\\                    & = \\frac{1}{2} \\left( \\mathtt{X} \\mathbf{\\theta} - \\mathbf{y} \\right)^\\top \\left( \\mathtt{X} \\mathbf{\\theta} - \\mathbf{y} \\right)\n",
    "\\end{align}$$\n",
    "Here we've used $\\mathtt{X}$ to denote the design matrix and $\\mathbf{y}$ to denote the vector$$\\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_m \\end{bmatrix} $$\n",
    "\n",
    "We'll see in a moment how to minimize this cost function.\n",
    "\n",
    "## Exercise 1.3 (2 point)\n",
    "\n",
    "Let's implement **cost function** in Python by these steps:\n",
    "\n",
    " 1. Calculate $dy = \\hat{y} - y = \\mathtt{X}\\theta - y$\n",
    " 2. Calcuate $cost = \\frac{1}{2}{dy}^T{dy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b62146fc38d54da4e5d69be496eda66",
     "grade": false,
     "grade_id": "cell-e008cbe9a9204243",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    J = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93f06647dde1e4ec9d5678a006911e58",
     "grade": true,
     "grade_id": "cell-83bccafec48d594b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_test = np.array([0, 10])\n",
    "res = cost(theta_test, X, y)\n",
    "res2 = cost(theta_test, X_data, y_data)\n",
    "\n",
    "print(res)\n",
    "print(res2)\n",
    "\n",
    "assert cost(theta_test, X, y) == 85.0, \"Data result is incorrect\"\n",
    "assert type(cost(theta_test, X_data, y_data)) == np.float64\n",
    "assert cost(np.array([3, 2]), np.array([[1, 2],[1, 8], [1, 4]]), np.array([10, 3, 8])) == 137.0, \"Function cost is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db459d16c0f2a1d47e7c87ec7d5389e1",
     "grade": false,
     "grade_id": "cell-4ae20ee5d53afd95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**: \\\n",
    "85.0 \\\n",
    "334551.1936199232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a518c0a7cbdd0f0577a87dda65ce6133",
     "grade": false,
     "grade_id": "cell-518cd75fb18219c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aside: minimizing a convex function using the gradient\n",
    "\n",
    "To solve our linear regression problem, we want to minimize the cost function $J(\\mathbf{\\theta})$ above with respect to the parameters $\\mathbf{\\theta}$.\n",
    "\n",
    "$J$ is convex (see <code>[Wikipedia](https://en.wikipedia.org/wiki/Convex_function)</code> for an explanation) so it has just one minimum for some specific value of $\\mathbf{\\theta}$.\n",
    "\n",
    "To find this minimum, we will find the point at which the gradient is equal to the zero vector.\n",
    "\n",
    "The gradient of a multivariate function at a particular point is a vector pointing in the direction of maximum slope with a magnitude indicating the slope of the tangent at that point.\n",
    "\n",
    "To make this clear, let's consider an example in which we consider the function $f(x) = 4x^2 - 6x + 11$ on the interval $[-10, 10]$ and plot its tangent lines at regular intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range for plotting x\n",
    "x = np.arange(-10, 10, 1)\n",
    "\n",
    "# Example function f(x)\n",
    "def f(x):\n",
    "    return 4 * x * x - 6 * x + 11\n",
    "\n",
    "# Plot f(x)\n",
    "plt.plot(x, f(x), 'g')\n",
    "\n",
    "# First derivative of f(x)\n",
    "def dfx(x):\n",
    "    return 8 * x - 6\n",
    "\n",
    "# Plot tangent lines for f(x)\n",
    "for i in np.arange(-10,10,3):\n",
    "    x_i = np.arange(i - 1.0, i + 1.0, .25)\n",
    "    m_i = dfx(i)\n",
    "    c =  f(i) - m_i*i\n",
    "    y_i = m_i*(x_i)  +  c\n",
    "    plt.plot(x_i,y_i,'b')\n",
    "\n",
    "# Plot tangent line at the minimum of f(x)\n",
    "minimum = 0.75\n",
    "\n",
    "for i in [minimum]:\n",
    "    x_i = np.arange(i - 1, i + 1, .5)\n",
    "    m_i = dfx(i)\n",
    "    c = f(i) - m_i * i\n",
    "    y_i = m_i * (x_i) + c\n",
    "    plt.plot(x_i, y_i, 'r-', label='Local minimum')\n",
    "\n",
    "# Decorate the plot\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Minimization example')\n",
    "plt.grid(axis='both',color='c', alpha=0.25)\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87bb5a26e439e7060892a5671179ed79",
     "grade": false,
     "grade_id": "cell-d251375d3528afd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Minimizing the cost function\n",
    "\n",
    "Based on the previous example, we can see that to minimize our cost function, we just need to take the gradient with respect to $\\mathbf{\\theta}$ and determine where that gradient is equal to $\\mathbf{0}$.\n",
    "\n",
    "We have\n",
    "$$ J(\\mathbf{\\theta}) = \\frac{1}{2} \\sum_{i=1}^{m} \\left(h_\\mathbf{\\theta}(\\mathbf{x}^{(i)}) - y^{(i)}\\right)^2 .$$\n",
    "This is a convex function of two variables ($\\theta_0$ and $\\theta_1$), so it has a single minimum where the gradient $\\nabla_J(\\mathbf{\\theta})$ is $\\mathbf{0}$.\n",
    "\n",
    "Depending on the specific data, the cost function will look something like the surface plotted by the following code. Regardless of where we begin, the gradient always points \"uphill,\" away from the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a sample 2D squared error cost function\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x1 = np.linspace(-5.0, 15.0, 100)\n",
    "x2 = np.linspace(-12.0, 8.0, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "Y = (np.square(X1 - np.mean(X1)) + np.square(X2 - np.mean(X2))) + 10\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.set_xlabel('theta_0')\n",
    "ax.set_ylabel('theta_1')\n",
    "ax.set_zlabel('J')\n",
    "ax.set_title('Sample cost function for linear regression')\n",
    "cm = plt.cm.get_cmap('viridis')\n",
    "ax.plot_surface(X1, X2, Y, cmap=cm)\n",
    "ax.view_init(elev=25, azim=55)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d00531db8272ef1ad3926b59399bcb09",
     "grade": false,
     "grade_id": "cell-a786965b72a62bb2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take a look at the lecture notes. If you obtain the partial derivatives of the cost function $J$ with respect to $\\mathbf{\\theta}$, you get\n",
    "\n",
    "$$ \\nabla_J(\\mathbf{\\theta}) = \\mathtt{X}^\\top (\\mathtt{X}\\mathbf{\\theta}-\\mathbf{y}).$$\n",
    "\n",
    "## Exercise 1.4 (2 point)\n",
    "\n",
    "Write **gradient function** in python code from equation above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81de4ba12d6a820cad122d8accbeab6b",
     "grade": false,
     "grade_id": "cell-542b93a6ad8d77a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of cost function\n",
    "def gradient(X, y, theta):\n",
    "    grad = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b271b05d63367585123dd071a7354c65",
     "grade": true,
     "grade_id": "cell-f12dbedf58c2f1fc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "res = gradient(X, y, theta_test)\n",
    "res2 = gradient(X_data, y_data, theta_test)\n",
    "\n",
    "print(res)\n",
    "print(res2)\n",
    "\n",
    "assert res.shape == 2 or res.shape[0] == 2, \"gradient shape is incorrect\"\n",
    "assert res2.shape == 2 or res2.shape[0] == 2, \"gradient shape is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4853e17385ea108812187def7f40258e",
     "grade": false,
     "grade_id": "cell-13c11141edda9e2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**: \\\n",
    "[-10, -13] \\\n",
    "[ 7348.6099     72624.92611208]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84e706caab66fcb48cc0bef1a135e664",
     "grade": false,
     "grade_id": "cell-8a8713533d55c301",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This means that if we currently had the parameter vector [0, 10] (where the cost is 85) and wanted to increase the cost, we could move in the direction [-10, -13]. On the other hand, if we wanted to decrease the cost (which of course we do), we should move in the opposite direction, i.e., [10, 13]. \n",
    "\n",
    "Recall that the parameters of your model are the $\\theta$ values. These are\n",
    "the values you will adjust to minimize cost $J(\\theta)$. To do this is to use the batch gradient descent algorithm. In batch gradient descent, each iteration performs the update\n",
    "\n",
    "$$\\theta=\\theta-\\alpha\\frac{1}{m} \\sum_{i=1}^{m} \\left(h_\\mathbf{\\theta}(\\mathbf{x}^{(i)}) - y^{(i)}\\right)x^{(i)}_j$$\n",
    "$$\\theta = \\theta - \\alpha * \\nabla_J(\\mathbf{\\theta})$$\n",
    "\n",
    "Simultaneously update $\\theta$ for all $j$\n",
    "\n",
    "## Exercise 1.5 (2 point)\n",
    "\n",
    "Implement this idea of gradient descent:\n",
    "\n",
    "1. Calculate gradient from $X$, $y$ and $\\theta$ using function <code>gradient</code>\n",
    "2. Update $\\theta_{new} = \\theta + {\\alpha}*grad$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb457bed034a3eaa55163752c7343813",
     "grade": false,
     "grade_id": "cell-ef9adb54e461a3b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta_initial, alpha, num_iters):\n",
    "    J_per_iter = np.zeros(num_iters)\n",
    "    gradient_per_iter = np.zeros((num_iters,len(theta_initial)))\n",
    "    # initialize theta\n",
    "    theta = theta_initial\n",
    "    for iter in np.arange(num_iters):\n",
    "        grad = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        J_per_iter[iter] = cost(theta, X, y)\n",
    "        gradient_per_iter[iter] = grad.T\n",
    "    return (theta, J_per_iter, gradient_per_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0d2a5557b25b744fb3797ff91ed5c50",
     "grade": true,
     "grade_id": "cell-7688307b7f186c2f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(theta, J_per_iter, gradient_per_iter) = gradient_descent(X, y, theta_test, 0.001, 10)\n",
    "(theta2, J_per_iter2, gradient_per_iter2) = gradient_descent(X_data, y_data, theta_test, 0.001, 10)\n",
    "\n",
    "print(\"theta:\", theta)\n",
    "print(\"J_per_iter:\", J_per_iter)\n",
    "print(\"gradient_per_iter\", gradient_per_iter)\n",
    "\n",
    "print(\"theta2:\", theta2)\n",
    "print(\"J_per_iter2:\", J_per_iter2)\n",
    "print(\"gradient_per_iter2\", gradient_per_iter2)\n",
    "\n",
    "assert (theta.shape[0] == 2 or theta.shape == 2) and (theta2.shape[0] == 2 or theta2.shape == 2), \"theta shape is incorrect\"\n",
    "assert len(J_per_iter) == 10 and len(J_per_iter2) == 10, \"J history shape is incorrect\"\n",
    "assert gradient_per_iter.shape == (10,2) and gradient_per_iter2.shape == (10,2), \"gradient history is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eadbb09e2e4a66eaa87eacd693646dbf",
     "grade": false,
     "grade_id": "cell-9b61d6369cd11d72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**: \\\n",
    "theta: [ 0.08327017 10.02116759]\\\n",
    "J_per_iter: [84.775269   84.65958757 84.5793525  84.51074587 84.44605981 84.38279953\\\n",
    " 84.32015717 84.25787073 84.19585485 84.13408132]\\\n",
    "gradient_per_iter [[-10.         -13.        ]\\\n",
    " [ -9.084       -6.894     ]\\\n",
    " [ -8.556648    -3.421524  ]\\\n",
    " [ -8.25039038  -1.4471287 ]\\\n",
    " [ -8.06991411  -0.32491618]\\\n",
    " [ -7.96100025   0.31253312]\\\n",
    " [ -7.8928063    0.67422616]\\\n",
    " [ -7.84778746   0.87905671]\\\n",
    " [ -7.81596331   0.9946576 ]\\\n",
    " [ -7.79165648   1.05950182]]\\\n",
    " theta2: [2.49586699e+08 2.48441765e+09]\\\n",
    "J_per_iter2: [1.62549391e+07 7.90946753e+08 3.84877236e+10 1.87282617e+12\\\n",
    " 9.11323816e+13 4.43453381e+15 2.15785978e+17 1.05002218e+19\\\n",
    " 5.10944492e+20 2.48627391e+22]\\\n",
    "gradient_per_iter2 [[ 7.34860990e+03  7.26249261e+04]\\\n",
    " [-5.08468779e+04 -5.06651170e+05]\\\n",
    " [ 3.55099975e+05  3.53420425e+06]\\\n",
    " [-2.47666950e+06 -2.46535791e+07]\\\n",
    " [ 1.72768901e+07  1.71975865e+08]\\\n",
    " [-1.20517969e+08 -1.19965161e+09]\\\n",
    " [ 8.40697246e+08  8.36840645e+09]\\\n",
    " [-5.86444912e+09 -5.83754701e+10]\\\n",
    " [ 4.09086221e+10  4.07209608e+11]\\\n",
    " [-2.85366163e+11 -2.84057095e+12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3575ef79d5529e018ce870ffa5a5c5c0",
     "grade": false,
     "grade_id": "cell-eab3fff256e736a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Optimize for parameters in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_initial = np.array([0, 0])\n",
    "alpha = 0.0001\n",
    "iterations = 3000\n",
    "theta, costs, grad = gradient_descent(X, y, theta_initial, alpha, iterations)\n",
    "print('Optimal parameters: theta_0 %f theta_1 %f' % (theta[0], theta[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.scatter(num_hours_studied, exam_score)\n",
    "\n",
    "x = np.linspace(0,10,20)\n",
    "y_predicted = theta[0] + theta[1] * x\n",
    "plt.plot(x, y_predicted, 'g', label='Prediction')\n",
    "\n",
    "plt.xlabel('num_hours_studied')\n",
    "plt.ylabel('exam_score')\n",
    "plt.legend();\n",
    "plt.title('Linear regression result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss\n",
    "x_loss = np.arange(0, iterations, 1)\n",
    "\n",
    "plt.plot(x_loss, costs, 'b-')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.6 (5 point)\n",
    "\n",
    "Optimize theta2 parameters in X_data and y_data using above functions.\n",
    "\n",
    "1. Define your own initial_theta, alpha, and iterations.\n",
    "2. The final cost2 must less than 435."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d06d416130975615433480dc363ca00d",
     "grade": false,
     "grade_id": "cell-6bbc52579fefd979",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_initial = None\n",
    "alpha = None\n",
    "iterations2 = None\n",
    "\n",
    "theta2, costs2, grad2 = None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8da51870d2af19fa18ef6e3ceb5d97c",
     "grade": true,
     "grade_id": "cell-0c75f9f189344c48",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Optimal parameters: theta_0 %f theta_1 %f' % (theta2[0], theta2[1]))\n",
    "print(cost(theta2, X_data, y_data))\n",
    "\n",
    "assert theta_initial.shape == theta2.shape, \"Theta initial shape must equal to theta\"\n",
    "assert theta2.shape == 2 or theta2.shape[0] == 2, \"theta shape is incorrect\"\n",
    "assert cost(theta2, X_data, y_data) < 435, \"Your cost function does not be optimized\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55ed3ac6f24f0fa97ce3d7aec038f8f0",
     "grade": false,
     "grade_id": "cell-b090398d37489cd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**:\\\n",
    "Optimal parameters: theta_0 -3.895781 theta_1 1.193034\\\n",
    "434.26622346959226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac2b2eeb13e3dfcfd35f1b13c5c6ac72",
     "grade": false,
     "grade_id": "cell-b401961d97042038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.7 (5 point)\n",
    "\n",
    "Plot regression graph of X_data, and y_data with your own theta2\n",
    "\n",
    "**hint**: to find the reasonable x value, use <code>np.min</code> and <code>np.max</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d461b26e35b3e9f22556371be5a26170",
     "grade": true,
     "grade_id": "cell-cce45cf07f1cb757",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expect result**:\n",
    "<img src=\"img/ex7expect.png\" title=\"Exersire Expect result\" style=\"width: 400px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ad3f6b418c9e846ac52a37eddca6dbe",
     "grade": false,
     "grade_id": "cell-55e5cdda95aba4d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Excercise 1.8 (2 point)\n",
    "\n",
    "From cost plotting graph at above, please create it as function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35f5fe2fc10fdff777e0c303b5a62e34",
     "grade": false,
     "grade_id": "cell-6f9dcc1e54a44ed4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost_plot(iterations, costs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70972032c054eb372d2c001905967afd",
     "grade": true,
     "grade_id": "cell-42ff4369a5f33e55",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cost_plot(iterations, costs)\n",
    "cost_plot(iterations2, costs2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expect result**:\n",
    "\n",
    "<img src=\"img/ex8expect1.png\" title=\"Exersire Expect result\" style=\"width: 400px;\" />\n",
    "<img src=\"img/ex8expect2.png\" title=\"Exersire Expect result\" style=\"width: 400px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba2889e412c73eeea307864d651e0e8b",
     "grade": false,
     "grade_id": "cell-54cb5be6ead8690a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can conclude from the loss curve that we have achieved convergence (the loss has stopped improving), and we can conclude that 3000 iterations is overkill! The loss is stable after 100 iterations or so.\n",
    "\n",
    "### Goodness of fit\n",
    "$R^2$ is a statistic that will give some information about the goodness of fit of a regression model.\n",
    "The sum squared regression is the sum of the residuals squared, and the total sum of squares is the sum of the distance the data is away from the mean all squared. As it is a percentage it will take values between 0 and 1.\n",
    "\n",
    "The $R^2$ coefficient of determination is 1 when the regression predictions perfectly fit the data. When $R^2$ is less than 1, it indicates the percentage of the variance in the target that is accounted for by the prediction.\n",
    "\n",
    "if output of $R^2$ less than 0, it means that $R^2$ is 0. None of the variation in the prediction is accounted for by the input values\n",
    "\n",
    "$$\\begin{align}\n",
    "\\ R^2 = 1 - \\frac{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\hat{y}^\\left(i\\right) \\right)^2}\n",
    "{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\bar{y}^\\left(i\\right) \\right)^2}\n",
    "\\end{align}$$\n",
    "\n",
    "## Exercise 1.9 (3 point)\n",
    "\n",
    "Create **goodnees of fit** function by using the equation at above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f99a77d10ed74b701bb63e9be6498fe8",
     "grade": false,
     "grade_id": "cell-b634b8c95cc9acb4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def goodness_of_fit(y, y_predicted):\n",
    "    r_square = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29fa486aa53e06d9a523f7a7bf2c8b56",
     "grade": true,
     "grade_id": "cell-edcf8a1f24f95310",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = h(X, theta)\n",
    "r_square = goodness_of_fit(y, y_predicted)\n",
    "print(r_square)\n",
    "\n",
    "y_predicted2 = h(X_data, theta)\n",
    "r_square2 = goodness_of_fit(y_data, y_predicted2)\n",
    "print(r_square2)\n",
    "\n",
    "yhat =  h(X, np.array([0, 10]))\n",
    "yhat2 =  h(X, np.array([10, 0]))\n",
    "r2 = goodness_of_fit(y, yhat)\n",
    "r3 = goodness_of_fit(y, yhat2)\n",
    "assert np.round(r2, 5) == np.round(0.9740385950298487, 5), \"Function goodness_of_fit is incorrect\"\n",
    "assert r3 <= 0, \"Function goodness_of_fit is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d2439c99aebce0de32f18601dcbf87b",
     "grade": false,
     "grade_id": "cell-54ff3695aba46b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**: \\\n",
    "0.9786239731773175 \\\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "910225ce29a66f048dfb6bfbb82ba400",
     "grade": false,
     "grade_id": "cell-9eac8f260e7fccf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "An $R^2$ of 0.98 indicates an extremely good (outrageously good, in fact) fit to the data.\n",
    "\n",
    "## Multivariate linear regression\n",
    "\n",
    "Next, we extend to multiple variables. We'll use a data set from Andrew Ng's class. The data include two independent variables, \"Square Feet\" and \"Number of Bedrooms,\" and the dependent variable is \"Price.\"\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use numpy's genfromtxt function to load the data from the text file.\n",
    "\n",
    "raw_data = np.genfromtxt('Housing_data.txt',delimiter = ',', dtype=str);\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b056f86ed3d743714d673834ba9d78d1",
     "grade": false,
     "grade_id": "cell-6de92c1175605f5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we split the raw data (currently strings) into headers and the data themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract headers and data\n",
    "headers = raw_data[0,:];\n",
    "print(headers)\n",
    "data = np.array(raw_data[1:,:], dtype=float);\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of independent and dependent variables\n",
    "\n",
    "# Make three subplots, in one row and three columns\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(20)\n",
    "fig.subplots_adjust(left=.2, bottom=None, right=None, top=None, wspace=.2, hspace=.2)\n",
    "plt1 = plt.subplot(1,3,1)\n",
    "plt2 = plt.subplot(1,3,2)\n",
    "plt3 = plt.subplot(1,3,3)\n",
    "\n",
    "# Variable 1: square footage\n",
    "plt1.hist(data[:,0], label='Sq. feet', edgecolor='black')\n",
    "plt1.set_title('House Size')\n",
    "plt1.set_xlabel('units')\n",
    "plt1.set_ylabel('Frequency')\n",
    "plt1.grid(axis='both', alpha=.25)\n",
    "\n",
    "# Variable 2: number of bedrooms\n",
    "plt2.hist(data[:,1], label='Bedroom', edgecolor='black')\n",
    "plt2.set_title('Bedrooms')\n",
    "plt2.set_xlabel('units')\n",
    "plt2.set_ylabel('Frequency')\n",
    "plt2.grid(axis='both', alpha=.25)\n",
    "\n",
    "# Variable 3: home price\n",
    "plt3.hist(data[:,2], label='Price', edgecolor='black')\n",
    "plt3.set_title('Price')\n",
    "plt3.set_xlabel('units')\n",
    "plt3.set_ylabel('Frequency')\n",
    "plt3.grid(axis='both', alpha=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fafa81530c470b4106a0a92ffbbd55f",
     "grade": false,
     "grade_id": "cell-94788fb2b4f2f154",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Standardization\n",
    "We can see from the charts above that the independent variables and the dependent variables have very large differences in their ranges. If you try to use the gradient descent method on these data directly, you will have great difficulty in finding a learning rate that is small enough that the costs will not grow out of control but is large enough that the number of iterations is not excessive.\n",
    "\n",
    "Standardization can help with this. For each variable, we subtract that variable's mean from every instance then divide the result by the variable's standard deviation. The result will be a set of \"standardized\" variables with mean 0 and variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "means = np.mean(data, axis=0)\n",
    "stds = np.std(data, axis=0)\n",
    "data_norm = (data - means) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract y from normalized data\n",
    "y_label = 'Price'\n",
    "y_index = np.where(headers == y_label)[0][0]\n",
    "y = np.array([data_norm[:,y_index]]).T\n",
    "\n",
    "# Extract X from normalized data\n",
    "X = data_norm[:,0:y_index]\n",
    "\n",
    "# Insert column of 1's for intercept term\n",
    "X = np.insert(X, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of examples (m) and number of parameters (n)\n",
    "m = X.shape[0]\n",
    "n = X.shape[1]\n",
    "print(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a287c892c25edf3e63ccb34f1739369",
     "grade": false,
     "grade_id": "cell-42dcc4839c98720a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Excercise 1.10 (5 point)\n",
    "\n",
    "Optimize the parameters using gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f257ab1345d5a501992a6d25867f4f39",
     "grade": false,
     "grade_id": "cell-06acad01684251d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_initial = np.zeros((X.shape[1],1))\n",
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "theta, costs, grad = None, None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfb07a5a460415b73230d8dc42b9945b",
     "grade": true,
     "grade_id": "cell-2754c18559bfa20d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Theta values ', theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "194f2d3b14286100136e6512ce00678f",
     "grade": false,
     "grade_id": "cell-85973caececb5438",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**:\\\n",
    "Theta values  [[-9.15933995e-17]\\\n",
    " [ 8.84765988e-01]\\\n",
    " [-5.31788197e-02]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss over the optimization\n",
    "plt.title('Multivariate linear regression by gradient descent')\n",
    "cost_plot(iterations, costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1deb15b0dcb9f7b6d7994b98d066085",
     "grade": false,
     "grade_id": "cell-ac4e56806eb77334",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Transforming parameters back to the original scale\n",
    "Now that we've got optimal parameters for our original data, we need to undo the normalization.\n",
    "\n",
    "We have\n",
    "\n",
    "$$\\hat{y}^{\\text{norm}} = \\theta^\\text{norm} \\textbf{x}^\\text{norm}$$\n",
    "\n",
    "## Excercise 1.11 (2 point)\n",
    "\n",
    "Compute goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9b336d9d594652bce7588f9abea8740",
     "grade": false,
     "grade_id": "cell-6189182a5a60f3f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Goodness of fit\n",
    "y_predicted =  h(X,theta)\n",
    "r_square = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3852ac85c56a593c7e9e8cbc3ae5d235",
     "grade": true,
     "grade_id": "cell-6dc4d5d6bc562166",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ff250a5fbab4267e113270985de24d1",
     "grade": false,
     "grade_id": "cell-f19916d1e930779e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Transform standardized data back to original scale\n",
    "We can transform standardized predicted values, y_predicted into the orginal data scale using$$y_{\\text{norm}} = \\sigma_y y + \\mu_y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation of data\n",
    "\n",
    "sigma = np.array(np.std(data,axis=0))\n",
    "mu = np.array(np.mean(data,axis=0))\n",
    "\n",
    "# De-normalize y\n",
    "\n",
    "y_predicted =  np.round(h(X, theta) * sigma[2] + mu[2])\n",
    "\n",
    "# Print first five values of y_predicted\n",
    "\n",
    "print(y_predicted[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot of standardized data\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "p = ax.scatter(X[:,1],X[:,2],y,edgecolors='black',c=data_norm[:,2],alpha=1)\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y')\n",
    "\n",
    "X1 = np.linspace(min(X[:,1]), max(X[:,1]), len(y))\n",
    "X2 = np.linspace(min(X[:,2]), max(X[:,2]), len(y))\n",
    "\n",
    "xx1,xx2 = np.meshgrid(X1,X2)\n",
    "\n",
    "yy = (theta[0] + theta[1]*xx1.T + theta[2]*xx2)\n",
    "ax.plot_surface(xx1,xx2,yy, alpha=0.5)\n",
    "ax.view_init(elev=25, azim=10)\n",
    "plt.colorbar(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b03625847034dd250ad288c57157375c",
     "grade": false,
     "grade_id": "cell-fd010ec56bee0626",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### In-class exercise\n",
    "Now that you're familiar with minimizing a cost function using its gradient and gradient descent, refer to the lecture notes to find the analytical solution (the normal equations) to the linear regression problem.\n",
    "\n",
    "Implement the normal equation approach for the synthetic univariate data set and the housing price data set. Demonstrate your solution in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d0c78951beda356aa79a2b24f68bd6b",
     "grade": false,
     "grade_id": "cell-e8c0cbe448d8edf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# just remove all parameters\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b10ee27ac7f963a889b1590e38b3c7f2",
     "grade": false,
     "grade_id": "cell-538b321ed5c8c479",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.1 (3 point)\n",
    "Download raw_data and setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "467e8cd987b79d891991353b3a33d090",
     "grade": false,
     "grade_id": "cell-8ec5005213656ad7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Download raw_data and setup data\n",
    "data = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5da64d9214fdf4357cf00a8a6669f52b",
     "grade": true,
     "grade_id": "cell-684e4a35be532463",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(data[:5])\n",
    "\n",
    "assert np.array_equal(np.round(data[7], 5), np.round([1.42700e+03, 3.00000e+00, 1.98999e+05], 5)), \"data is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8199024597567bcf29edd1137ad61cb",
     "grade": false,
     "grade_id": "cell-d4ad8dd0267769b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**:\\\n",
    "[[2.104e+03 3.000e+00 3.999e+05]\\\n",
    " [1.600e+03 3.000e+00 3.299e+05]\\\n",
    " [2.400e+03 3.000e+00 3.690e+05]\\\n",
    " [1.416e+03 2.000e+00 2.320e+05]\\\n",
    " [3.000e+03 4.000e+00 5.399e+05]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "957aa1816e72a4064afe2085a99c1b2d",
     "grade": false,
     "grade_id": "cell-0859396b500237fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.2 (5 point)\n",
    "Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce54ce21ec3cd487dd74b0dad8111948",
     "grade": false,
     "grade_id": "cell-0c303e363a86e0e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalized data\n",
    "def normalized_data(data):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b5b1025dc8b35b7961e59d81ef93b98",
     "grade": true,
     "grade_id": "cell-666a35687df87e4b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_norm = normalized_data(data)\n",
    "print(data_norm[:5])\n",
    "\n",
    "assert np.array_equal(np.round(data_norm[7], 5), np.round([-0.72968575, -0.22609337, -1.1431751 ], 5)), \"data is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a830e2ada8be3a89530cedc6d6f121e",
     "grade": false,
     "grade_id": "cell-3ac03ac4ad570ac5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**:\\\n",
    "[[ 0.13141542 -0.22609337  0.48089023]\\\n",
    " [-0.5096407  -0.22609337 -0.08498338]\\\n",
    " [ 0.5079087  -0.22609337  0.23109745]\\\n",
    " [-0.74367706 -1.5543919  -0.87639804]\\\n",
    " [ 1.27107075  1.10220517  1.61263744]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b49df4a50480feff80e56707d8f4714",
     "grade": false,
     "grade_id": "cell-283aafc0a867da58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.3 (5 point)\n",
    "Extract X and y from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0969ce7e4f423bb7a6aa3e01c1505fc3",
     "grade": false,
     "grade_id": "cell-8ffcfa2cd2adaa33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract y from data\n",
    "y = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f3205349e2e26e9fe11ba5676e78aa",
     "grade": true,
     "grade_id": "cell-b770588a9dedd56d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(y[:5])\n",
    "\n",
    "assert np.array_equal(np.round(y[10:14], 5), np.round([-0.81173485,  0.05325146, -0.08418307,  2.90606282], 5)), \"data is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4da7d5be8fea57b60778f7d281f5afe",
     "grade": false,
     "grade_id": "cell-58b1ba88b8eeaf46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**: [ 0.48089023 -0.08498338  0.23109745 -0.87639804  1.61263744]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "321ec7e95d6c1dc445ae106f2268ed80",
     "grade": false,
     "grade_id": "cell-92ceac829e8cb196",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract X from data\n",
    "X = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fc537da0450238a851b7a4acd3efa4f",
     "grade": true,
     "grade_id": "cell-717b8a1c64724282",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(X[:5,:])\n",
    "\n",
    "assert np.array_equal(np.round(X[10,:], 5), np.round([ 1., -0.0771822, 1.10220517], 5)), \"data is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d57ddedc69abcb25981cfaeda48722fa",
     "grade": false,
     "grade_id": "cell-a3bc80814584e014",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**:\\\n",
    "[[ 1.          0.13141542 -0.22609337]\\\n",
    " [ 1.         -0.5096407  -0.22609337]\\\n",
    " [ 1.          0.5079087  -0.22609337]\\\n",
    " [ 1.         -0.74367706 -1.5543919 ]\\\n",
    " [ 1.          1.27107075  1.10220517]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5836ae288ffbe73a5f3485800c75ec1",
     "grade": false,
     "grade_id": "cell-fd3883eff0960005",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.4 (8 point)\n",
    "Create h, cost, gradient, and gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeb98571a0e431a0bef62b6fe615c871",
     "grade": false,
     "grade_id": "cell-687607f0da0d7abb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create h function\n",
    "def h(X,theta):\n",
    "    y_predicted = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "600f5b8af5d82ae386b1f3fc8618e2ac",
     "grade": true,
     "grade_id": "cell-d957e149102d4dd8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(h(X, np.array([1, 2, 4]))[:5])\n",
    "\n",
    "assert res.shape == (X.shape[0],), \"Data size in result is incorrect\"\n",
    "assert np.array_equal(np.round(h(X, np.array([1, 3, 10]))[:5], 5), np.round([-0.86668741,-2.78985577,0.26279242,-16.7749502,15.83526391],5)), \"Function h is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77b4de27099245dc4d0b1053837d199f",
     "grade": false,
     "grade_id": "cell-c611d33ee8306391",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**: [ 0.35845737 -0.92365487  1.11144393 -6.70492173  7.95096216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eddca10dce80035ffffc52bbd18e4da",
     "grade": false,
     "grade_id": "cell-8031aef056c58451",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    J = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c2937e4cd20224bbead86d8c08cb617",
     "grade": true,
     "grade_id": "cell-13b68cd3acbc1871",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(cost(np.array([1, 8, 10]), X, y))\n",
    "\n",
    "assert np.round(cost(np.array([1, 8, 10]), X, y), 5) == np.round(5477.13863, 5), \"Data result is incorrect\"\n",
    "assert np.round(cost(np.array([2, 1, 2]), X, y), 5) == np.round(205.8799553398718, 5), \"Function cost is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d738f5d005f9236d47fc41b9b121bd58",
     "grade": false,
     "grade_id": "cell-199d8d7d4540b85e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**: 5477.138628374691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b81c528c42f8a7f17330a34b6de79d5",
     "grade": false,
     "grade_id": "cell-727893bbdd504a71",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of cost function\n",
    "def gradient(X, y, theta):\n",
    "    grad = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ad6370a08edea41babbcae75c3556e7",
     "grade": true,
     "grade_id": "cell-8eeb9b2e6bc37c85",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(gradient(X, y, np.array([1, 8, 10])))\n",
    "\n",
    "assert np.array_equal(np.round(gradient(X, y, np.array([3.1, -2.1, 4.8])), 5), np.round([145.7,-12.55581557,149.54496443],5)), \"Function gradient is incorrect\"\n",
    "assert np.round(gradient(X, y, np.array([3.2, 1.0, 2.5]))[0] - gradient(X, y, np.array([3.2, 1.0, 2.5]))[1], 5) == np.round(77.78827035558807, 5), \"Data result is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b353c3f49a434e9ccfb46ae3f7e84b4",
     "grade": false,
     "grade_id": "cell-58ba3606c3df1a48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**: [ 47.         599.00016917 659.76139633]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b89d36928aa93893f739c950fc8174f",
     "grade": false,
     "grade_id": "cell-b715505ba6c0fa23",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta_initial, alpha, num_iters):\n",
    "    J_per_iter = np.zeros(num_iters)\n",
    "    gradient_per_iter = np.zeros((num_iters,len(theta_initial)))\n",
    "    # initialize theta\n",
    "    theta = theta_initial\n",
    "    for iter in np.arange(num_iters):\n",
    "        grad = None\n",
    "        # update theta\n",
    "        # theta = None\n",
    "        J = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        J_per_iter[iter] = J\n",
    "        gradient_per_iter[iter] = grad.T\n",
    "    return (theta, J_per_iter, gradient_per_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3552c7b527ab1f45a0420e13ab6fc5a7",
     "grade": true,
     "grade_id": "cell-b60403692e08f361",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(theta, J_per_iter, gradient_per_iter) = gradient_descent(X, y, np.array([0, 1, 10]), 0.001, 10)\n",
    "print(\"theta:\", theta)\n",
    "print(\"J_per_iter:\", J_per_iter)\n",
    "print(\"gradient_per_iter\", gradient_per_iter)\n",
    "\n",
    "assert np.array_equal(np.round(theta, 2), np.round([-8.20787882e-16,-7.72838948e-01,6.35294636e+00], 2)), \"the data result in theta is incorrect\"\n",
    "assert np.round(gradient_per_iter[5, 0], 5) == np.round(1.11022302e-13, 5), \"the data result in gradient_per_iter is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b8bac715088c1a8a013c44190a58cda",
     "grade": false,
     "grade_id": "cell-402bb23146f668b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**:\n",
    "theta: [-8.20787882e-16 -7.72838948e-01  6.35294636e+00]\\\n",
    "J_per_iter: [2123.51284628 1873.56259758 1656.90935568 1468.93187452 1305.65834104\\\n",
    " 1163.67477334 1040.04635308  932.24986509  838.11567544  755.77790087]\\\n",
    "gradient_per_iter [[1.31450406e-13 2.70000169e+02 4.75532186e+02]\\\n",
    " [9.68114477e-14 2.44794887e+02 4.46076185e+02]\\\n",
    " [9.63673585e-14 2.21549490e+02 4.18667980e+02]\\\n",
    " [8.92619312e-14 2.00117968e+02 3.93159744e+02]\\\n",
    " [1.11022302e-13 1.80365065e+02 3.69414440e+02]\\\n",
    " [7.40518757e-14 1.62165488e+02 3.47305031e+02]\\\n",
    " [5.05151476e-14 1.45403177e+02 3.26713748e+02]\\\n",
    " [6.09512441e-14 1.29970626e+02 3.07531415e+02]\\\n",
    " [6.29496455e-14 1.15768253e+02 2.89656812e+02]\\\n",
    " [4.74065232e-14 1.02703825e+02 2.72996100e+02]]\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d661ddcb795e0576fb9cce83bd350c96",
     "grade": false,
     "grade_id": "cell-d727884d390c5e77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.5 (5 point)\n",
    "\n",
    "Do optimization using gradient descent with $\\alpha = 0.003$ and 30,000 iterations. The theta_initial is zero-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b15c3ba81b4bea9bbb051a9fb68472e6",
     "grade": false,
     "grade_id": "cell-bf04058de1bcc1fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_initial = None\n",
    "alpha = None\n",
    "iterations = None\n",
    "\n",
    "theta, costs, grad = None, None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c5307bf6d2b6ad34951c1a82bb88948",
     "grade": true,
     "grade_id": "cell-a940fb3166647683",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"theta:\", theta)\n",
    "print(\"cost_per_iter:\", costs[-5:])\n",
    "print(\"gradient_per_iter\", grad[-5:])\n",
    "\n",
    "assert alpha == 0.003, \"initial alpha is incorrect\"\n",
    "assert iterations == 30000, \"initial iteration is incorrect\"\n",
    "assert np.array_equal(np.round(theta, 5), np.round([-1.05832010e-16,8.84765988e-01,-5.31788197e-02], 5)), \"the data result in theta is incorrect\"\n",
    "assert np.round(grad[2, 1], 5) == np.round(-2.70822645e+01, 5), \"the data result in gradient_per_iter is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88f6f6fa23ed77fd19b5ee0f5552eff5",
     "grade": false,
     "grade_id": "cell-3ae5422c1168d02d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**:\\\n",
    "theta: [-1.05832010e-16  8.84765988e-01 -5.31788197e-02]\\\n",
    "J_per_iter: [6.27579208 6.27579208 6.27579208 6.27579208 6.27579208]\\\n",
    "gradient_per_iter [[ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "516eb3001d4e3f7eea6509b58e04c474",
     "grade": false,
     "grade_id": "cell-8ccc1a736758244e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.6 (2 point)\n",
    "\n",
    "Calculate goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b708c416226df726e9802eaa2d437c7",
     "grade": false,
     "grade_id": "cell-5d3692752f6fbab2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def goodness_of_fit(y, y_predicted):\n",
    "    r_square = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5a93042d6978ae4b25afcddef27f141",
     "grade": true,
     "grade_id": "cell-f772768c21ce0ea6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_predicted =  h(X, theta)\n",
    "r_square = goodness_of_fit(y, y_predicted)\n",
    "print(r_square)\n",
    "\n",
    "assert np.array_equal(np.round(r_square, 5), np.round(0.7329450180289143, 5)), \"result of r_square is incorrect\"\n",
    "assert np.round(r_square, 5) == np.round(0.7329450180289143, 5), \"result of r_square is incorrect\"\n",
    "yhat =  h(X, np.array([0, 1, 10]))\n",
    "r2 = goodness_of_fit(y, yhat)\n",
    "assert np.round(r2, 5) == np.round(-101.6441465600189, 5), \"Function goodness_of_fit is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e608b9ec1eaefdb4bc1743a4a2b145e1",
     "grade": false,
     "grade_id": "cell-222da897ae9c62bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**: 0.7329450180289143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "321fc8eadb95a2c82541b47082971195",
     "grade": false,
     "grade_id": "cell-4a1c9001937ca857",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Excercise 2.7 (2 point)\n",
    "\n",
    "Plot graph of cost results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdd8f8022997cb5611b74deec9006da4",
     "grade": true,
     "grade_id": "cell-b4869512362ab6cd",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost_plot(iterations, costs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "cost_plot(iterations, costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80230ce2e13070bad113c1bca1598689",
     "grade": false,
     "grade_id": "cell-05006048af4fd496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.8 (7 point)\n",
    "\n",
    "Write the function of **normal equation** and write normal equation code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1826488bd0ef0040bbdcb5fb9979919",
     "grade": true,
     "grade_id": "cell-04f0dd05ded72933",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "248543be3992cb2363f4237062128a8e",
     "grade": false,
     "grade_id": "cell-613b033259c6ef42",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# write normal equation code\n",
    "def normal_equation(X,y):\n",
    "    theta_norm = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return theta_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0a1b63778c44667f4fb751bb172ecd5",
     "grade": true,
     "grade_id": "cell-3f75014dc83a1372",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_norm = normal_equation(X,np.array([y]).T)\n",
    "print(\"theta from normal equation:\", theta_norm.T)\n",
    "y_norm_predicted =  h(X, theta_norm)\n",
    "r_norm_square = goodness_of_fit(y, y_norm_predicted)\n",
    "print(\"r_square:\", r_norm_square)\n",
    "\n",
    "assert np.array_equal(np.round(theta_norm.T, 5), np.round([[-7.90434550e-17,8.84765988e-01,-5.31788197e-02]], 5)), \"the data result in theta is incorrect\"\n",
    "assert np.array_equal(np.round(r_norm_square, 5), np.round(0.7329450180289143, 5)), \"result of r_square is incorrect\"\n",
    "assert np.round(r_norm_square, 5) == np.round(0.7329450180289143, 5), \"result of r_square is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce11836dcb582e0b7e0c84d331806f35",
     "grade": false,
     "grade_id": "cell-160c14bd432b8075",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect Result**:\\\n",
    "theta from normal equation: [[-7.90434550e-17  8.84765988e-01 -5.31788197e-02]]\\\n",
    "r_square: 0.7329450180289143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76864632f31d53d8078f567983459f83",
     "grade": false,
     "grade_id": "cell-0c27f43b5c40a687",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Take-home exercise (30 points)\n",
    "Use ``lab1data2.txt\" to implement the normal equations and gradient descent then evaluate your model's performance.\n",
    "\n",
    "Write a brief report on your experiments and results in the form of a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "315b77ce9d9b39f9cf76936a6e4e2ddb",
     "grade": false,
     "grade_id": "cell-97cac4f2657fe8e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Explain the dataset which you get and which rows which you use.\n",
    "How many data in your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fdc116ce5f8e958dd37874cda253742",
     "grade": true,
     "grade_id": "cell-fc743a8c603c95fb",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2da20c2ecc97760cb3843751df5edb9c",
     "grade": false,
     "grade_id": "cell-16cb90ab7980490c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write down your all code at below.\n",
    "Show the results, goodness of fit and plot cost graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "833b65d1c0eeff4686d434c924eae5e5",
     "grade": true,
     "grade_id": "cell-54284c2d3a5a5544",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
