{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "355a217ba750748ff309f9c52df0aea5",
     "grade": false,
     "grade_id": "cell-59e6313957d4919c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "In this lab, we'll take a look at how to build and evaluate linear regression models. Linear regression works well when there is an (approximately) linear relationship between the features and the variable we're trying to predict.\n",
    "\n",
    "Before we start, let's import the Python packages we'll need for the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d028e30de4d05425c33009198982dff",
     "grade": false,
     "grade_id": "cell-1c10d796359f5ff9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Univariate example\n",
    "Here's an example from <code>[Tim Niven's tutorial at Kaggle](https://www.kaggle.com/timniven/linear-regression-tutorial)</code>.\n",
    "\n",
    "### Background\n",
    "We would like to perform *univariate* linear regression using a single feature $x$, \"Number of hours studied,\" to predict a single dependent variable, $y$, \"Exam score.\"\n",
    "\n",
    "We can say that we want to regress <code>num_hours_studied</code> onto <code>exam_score</code> in order to obtain a model to predict a student's exam score using the number of hours he or she studied.\n",
    "\n",
    "In the standard setting, we assume that the dependent variable (the exam score) is a random variable that has a Gaussian distribution whose mean is a linear function of the independent variable(s) (the number of hours studied) and whose variance is unknown but constant:\n",
    "\n",
    "\\begin{equation}\n",
    "y\\sim\\mathcal{N}(\\theta_0+\\theta_1x,\\sigma^2)\n",
    "\\end{equation}\n",
    "\n",
    "Our model or hypothesis, then, will be a function predicting $y$ based on $x$:\n",
    "\\begin{equation}\n",
    "h_\\theta(x)=\\theta_0+\\theta_1x\n",
    "\\end{equation}\n",
    "\n",
    "Next we'll do something very typical in machine learning experiment: generate some synthetic data for which we know the \"correct\" model, then use those data to test our algorithm for finding the best model.\n",
    "\n",
    "So let's generate some example data and examine the relationship between $x$ and $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Independent variable\n",
    "num_hours_studied = np.array([1, 3, 3, 4, 5, 6, 7, 7, 8, 8, 10])\n",
    "\n",
    "# Dependent variable\n",
    "exam_score = np.array([18, 26, 31, 40, 55, 62, 71, 70, 75, 85, 97])\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(num_hours_studied, exam_score)\n",
    "plt.xlabel('num_hours_studied')\n",
    "plt.ylabel('exam_score')\n",
    "plt.title('Synthetic Exam Score Data Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f570d8a01ac757ab2026c6ba50eb84e9",
     "grade": false,
     "grade_id": "cell-8b0260aa73a1656f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Design Matrix\n",
    "The design matrix, usually written $\\mathtt{X}$, contains our independent variables.\n",
    "\n",
    "In general, with $m$ data points and $n$ features (independent variables), our design matrix will have $m$ rows and $n$ columns.\n",
    "\n",
    "Note that we have a parameter $\\theta_0$, which is the $y$-intercept term in our linear model. There is no independent variable to multiple $\\theta_0$, so we will introduced a dummy variable always equal to 1 to represent the independent variable corresponding to $\\theta_0$.\n",
    "\n",
    "Putting the dummy variable and the number of hours studied together, we obtain the design matrix\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathtt{X} = \\begin{bmatrix}\n",
    "    1 & 1\\\\\n",
    "    1 & 3\\\\\n",
    "    1 & 3\\\\\n",
    "    1 & 4\\\\\n",
    "    1 & 5\\\\\n",
    "    1 & 6\\\\\n",
    "    1 & 7\\\\\n",
    "    1 & 7\\\\\n",
    "    1 & 8\\\\\n",
    "    1 & 8\\\\\n",
    "    1 & 10\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation} \\\n",
    "Notice that we do **not** include the dependent variable (exam score) in the design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 2)\n",
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "# Add dummy variable for intercept term to design matrix.\n",
    "# Understand the numpy insert function by reading https://numpy.org/doc/stable/reference/generated/numpy.insert.html\n",
    "\n",
    "X = np.array([num_hours_studied]).T\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "y = exam_score\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dc0d850f12198341801c3e64d6e5c7b",
     "grade": false,
     "grade_id": "cell-d79875dbfd64ada5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "Let's rewrite the hypothesis function now that we have a dummy variable for the intercept term in the model. We can write the independent variables including the dummy variable as a vector\n",
    "\n",
    "$$\\mathbf{x} = \\begin{bmatrix} x_0 \\\\ x_1 \\end{bmatrix}, $$\n",
    "\n",
    "where $x_0 = 1$ is our dummy variable and $x_1$ is the number of hours studied. We also write the parameters as a vector\n",
    "\n",
    "$$\\mathbf{\\theta} = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\end{bmatrix} .$$\n",
    "\n",
    "Now we can conveniently write the hypothesis as\n",
    "\n",
    "$$ h_\\mathbf{\\theta}(\\mathbf{x}) = \\mathbf{\\theta}^\\top \\mathbf{x} . $$\n",
    "\n",
    "### Exercise 1 (2 points)\n",
    "\n",
    "Write a Python code function to evaluate a hypothesis $\\mathbf{\\theta}$ for an entire design matrix:\n",
    "\n",
    "**Hint**: Use numpy function of <code>dot</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f386219bc8c99a548f73c1f962ffcd83",
     "grade": false,
     "grade_id": "cell-997f03f005fa2365",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate hypothesis over a design matrix\n",
    "\n",
    "def h(X,theta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f9b13e884a26ffc5bd85334c1c84ac7",
     "grade": true,
     "grade_id": "cell-492acb5bb189c7b4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(h(X, np.array([0, 10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a07e4ecff86461f5581c6d3a76183b7",
     "grade": false,
     "grade_id": "cell-4df2b703a631f363",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**: [ 10,  30,  30,  40,  50,  60,  70,  70,  80,  80, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7efce36a20c1c834523c35c23f18699d",
     "grade": false,
     "grade_id": "cell-f0dbe51b109b574b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Cost function\n",
    "How can we find the best value of $\\mathbf{\\theta}$? We need a cost function and an algorithm to minimize that cost function.\n",
    "\n",
    "In a regression problem, we normally use squared error to measure the goodness of fit:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\ J(\\mathbf{\\theta}) & = \\frac{1}{2} \\sum_{i=1}^{m}\\left(h_\\mathbf{\\theta}\\left(\\mathbf{x}^{(i)}\\right) - y^{(i)}\\right)^2 \\\\\n",
    "\\                    & = \\frac{1}{2} \\left( \\mathtt{X} \\mathbf{\\theta} - \\mathbf{y} \\right)^\\top \\left( \\mathtt{X} \\mathbf{\\theta} - \\mathbf{y} \\right)\n",
    "\\end{align}$$\n",
    "Here we've used $\\mathtt{X}$ to denote the design matrix and $\\mathbf{y}$ to denote the vector$$\\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_m \\end{bmatrix} $$\n",
    "\n",
    "We'll see in a moment how to minimize this cost function.\n",
    "\n",
    "### Exercise 2 (2 points)\n",
    "\n",
    "Let's implement **cost function** in Python by these steps:\n",
    "\n",
    " 1. Calculate $dy = \\hat{y} - y = \\mathtt{X}\\theta - y$\n",
    " 2. Calcuate $cost = \\frac{1}{2}{dy}^T{dy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "679d49341ac0295d99b2a165dae94b4f",
     "grade": false,
     "grade_id": "cell-e008cbe9a9204243",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m = y.shape[0]\n",
    "\n",
    "def cost(theta, X, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "102b9931f951b594db05d5187643401e",
     "grade": true,
     "grade_id": "cell-83bccafec48d594b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(cost(np.array([0, 10]), X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1502fe59a99fc42167e79e2361dcf279",
     "grade": false,
     "grade_id": "cell-4ae20ee5d53afd95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**: 85.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a518c0a7cbdd0f0577a87dda65ce6133",
     "grade": false,
     "grade_id": "cell-518cd75fb18219c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aside: minimizing a convex function using the gradient\n",
    "\n",
    "To solve our linear regression problem, we want to minimize the cost function $J(\\mathbf{\\theta})$ above with respect to the parameters $\\mathbf{\\theta}$.\n",
    "\n",
    "$J$ is convex (see <code>[Wikipedia](https://en.wikipedia.org/wiki/Convex_function)</code> for an explanation) so it has just one minimum for some specific value of $\\mathbf{\\theta}$.\n",
    "\n",
    "To find this minimum, we will find the point at which the gradient is equal to the zero vector.\n",
    "\n",
    "The gradient of a multivariate function at a particular point is a vector pointing in the direction of maximum slope with a magnitude indicating the slope of the tangent at that point.\n",
    "\n",
    "To make this clear, let's consider an example in which we consider the function $f(x) = 4x^2 - 6x + 11$ on the interval $[-10, 10]$ and plot its tangent lines at regular intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range for plotting x\n",
    "x = np.arange(-10, 10, 1)\n",
    "\n",
    "# Example function f(x)\n",
    "def f(x):\n",
    "    return 4 * x * x - 6 * x + 11\n",
    "\n",
    "# Plot f(x)\n",
    "plt.plot(x, f(x), 'g')\n",
    "\n",
    "# First derivative of f(x)\n",
    "def dfx(x):\n",
    "    return 8 * x - 6\n",
    "\n",
    "# Plot tangent lines for f(x)\n",
    "for i in np.arange(-10,10,3):\n",
    "    x_i = np.arange(i - 1.0, i + 1.0, .25)\n",
    "    m_i = dfx(i)\n",
    "    c =  f(i) - m_i*i\n",
    "    y_i = m_i*(x_i)  +  c\n",
    "    plt.plot(x_i,y_i,'b')\n",
    "\n",
    "# Plot tangent line at the minimum of f(x)\n",
    "minimum = 0.75\n",
    "\n",
    "for i in [minimum]:\n",
    "    x_i = np.arange(i - 1, i + 1, .5)\n",
    "    m_i = dfx(i)\n",
    "    c = f(i) - m_i * i\n",
    "    y_i = m_i * (x_i) + c\n",
    "    plt.plot(x_i, y_i, 'r-', label='Local minimum')\n",
    "\n",
    "# Decorate the plot\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Minimization example')\n",
    "plt.grid(axis='both',color='c', alpha=0.25)\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e498f5afc1f4cc09e8661b3229fa3d08",
     "grade": false,
     "grade_id": "cell-d251375d3528afd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Minimizing the cost function\n",
    "\n",
    "Based on the previous example, we can see that to minimize our cost function, we just need to take the gradient with respect to $\\mathbf{\\theta}$ and determine where that gradient is equal to $\\mathbf{0}$.\n",
    "\n",
    "We have$$ J(\\mathbf{\\theta}) = \\frac{1}{2} \\sum_{i=1}^{m} \\left(h_\\mathbf{\\theta}(\\mathbf{x}^{(i)}) - y^{(i)}\\right)^2 .$$This is a convex function of two variables ($\\theta_0$ and $\\theta_1$), so it has a single minimum where the gradient $\\nabla_J(\\mathbf{\\theta})$ is $\\mathbf{0}$.\n",
    "\n",
    "Depending on the specific data, the cost function will look something like the surface plotted by the following code. Regardless of where we begin, the gradient always points \"uphill,\" away from the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a sample 2D squared error cost function\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x1 = np.linspace(-5.0, 15.0, 100)\n",
    "x2 = np.linspace(-12.0, 8.0, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "Y = (np.square(X1 - np.mean(X1)) + np.square(X2 - np.mean(X2))) + 10\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.set_xlabel('theta_0')\n",
    "ax.set_ylabel('theta_1')\n",
    "ax.set_zlabel('J')\n",
    "ax.set_title('Sample cost function for linear regression')\n",
    "cm = plt.cm.get_cmap('viridis')\n",
    "ax.plot_surface(X1, X2, Y, cmap=cm)\n",
    "ax.view_init(elev=25, azim=55)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45d81c5a81821191a5bb28e5e1354fcb",
     "grade": false,
     "grade_id": "cell-a786965b72a62bb2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take a look at the lecture notes. If you obtain the partial derivatives of the cost function $J$ with respect to $\\mathbf{\\theta}$, you get\n",
    "\n",
    "$$ \\nabla_J(\\mathbf{\\theta}) = \\mathtt{X}^\\top (\\mathtt{X}\\mathbf{\\theta}-\\mathbf{y}).$$\n",
    "\n",
    "### Exercise 3 (2 points)\n",
    "\n",
    "Write the gradient calculation in the equation above as a Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a365107e641d49f5710aebf59a168d21",
     "grade": false,
     "grade_id": "cell-542b93a6ad8d77a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of cost function\n",
    "\n",
    "def gradient(X, y, theta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47fea392e933a1e4d733247782f3e6b6",
     "grade": true,
     "grade_id": "cell-f12dbedf58c2f1fc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(gradient(X, y, np.array([0, 10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4c1080e43b37b5981aae9d783d63d8d",
     "grade": false,
     "grade_id": "cell-13c11141edda9e2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**: [-10, -13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34287245a72cdd94a8e2241ad964a046",
     "grade": false,
     "grade_id": "cell-8a8713533d55c301",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This means that if we currently had the parameter vector [0, 10] (where the cost is 85) and wanted to increase the cost, we could move in the direction [-10, -13]. On the other hand, if we wanted to decrease the cost (which of course we do), we should move in the opposite direction, i.e., [10, 13]. \n",
    "\n",
    "### Exercise 4 (2 points)\n",
    "\n",
    "Implement this idea of gradient descent:\n",
    "\n",
    "1. Calculate gradient from $X$, $y$ and $\\theta$ using function <code>gradient</code>\n",
    "2. Update $\\theta_{new} = \\theta + {\\alpha}*grad$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d22ece87334ae2637532926876e94fbe",
     "grade": false,
     "grade_id": "cell-ef9adb54e461a3b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta_initial, alpha, num_iters):\n",
    "    J_per_iter = np.zeros(num_iters)\n",
    "    gradient_per_iter = np.zeros((num_iters,len(theta_initial)))\n",
    "    # initialize theta\n",
    "    theta = theta_initial\n",
    "    for iter in np.arange(num_iters):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        J_per_iter[iter] = cost(theta, X, y)\n",
    "        gradient_per_iter[iter] = grad.T\n",
    "    return (theta, J_per_iter, gradient_per_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19db94c665c122c3e9735c9575fbd436",
     "grade": true,
     "grade_id": "cell-7688307b7f186c2f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(theta, J_per_iter, gradient_per_iter) = gradient_descent(X, y, np.array([0, 10]), 0.001, 10)\n",
    "print(\"theta:\", theta)\n",
    "print(\"J_per_iter:\", J_per_iter)\n",
    "print(\"gradient_per_iter\", gradient_per_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab00ce5b8450c6d63f488da7c1ecedea",
     "grade": false,
     "grade_id": "cell-9b61d6369cd11d72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**: \\\n",
    "theta: [ 0.08327017 10.02116759]\\\n",
    "J_per_iter: [84.775269   84.65958757 84.5793525  84.51074587 84.44605981 84.38279953\\\n",
    " 84.32015717 84.25787073 84.19585485 84.13408132]\\\n",
    "gradient_per_iter [[-10.         -13.        ]\\\n",
    " [ -9.084       -6.894     ]\\\n",
    " [ -8.556648    -3.421524  ]\\\n",
    " [ -8.25039038  -1.4471287 ]\\\n",
    " [ -8.06991411  -0.32491618]\\\n",
    " [ -7.96100025   0.31253312]\\\n",
    " [ -7.8928063    0.67422616]\\\n",
    " [ -7.84778746   0.87905671]\\\n",
    " [ -7.81596331   0.9946576 ]\\\n",
    " [ -7.79165648   1.05950182]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize parameters theta on dataset X, y\n",
    "\n",
    "theta_initial = np.array([0, 0])\n",
    "alpha = 0.0001\n",
    "iterations = 3000\n",
    "theta, costs, grad = gradient_descent(X, y, theta_initial, alpha, iterations)\n",
    "print('Optimal parameters: theta_0 %f theta_1 %f' % (theta[0], theta[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "\n",
    "plt.scatter(num_hours_studied, exam_score)\n",
    "\n",
    "x = np.linspace(0,10,20)\n",
    "y_predicted = theta[0] + theta[1] * x\n",
    "plt.plot(x, y_predicted, 'g', label='Prediction')\n",
    "\n",
    "plt.xlabel('num_hours_studied')\n",
    "plt.ylabel('exam_score')\n",
    "plt.legend();\n",
    "plt.title('Linear regression result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss\n",
    "\n",
    "x_loss = np.arange(0, iterations, 1)\n",
    "\n",
    "plt.plot(x_loss, costs, 'b-')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f38e5e796f6c8e5645e194d5082912f9",
     "grade": false,
     "grade_id": "cell-55e5cdda95aba4d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Excercise 5 (2 points)\n",
    "\n",
    "Instead of repeating the code to plot the loss graph, we would like to encapsulate the code in a function.\n",
    "Complete the loss plotting function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35f5fe2fc10fdff777e0c303b5a62e34",
     "grade": false,
     "grade_id": "cell-6f9dcc1e54a44ed4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost_plot(iterations, costs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03d69c1cba035e578d87dd3f423ca77a",
     "grade": true,
     "grade_id": "cell-42ff4369a5f33e55",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cost_plot(iterations, costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9650e1f1373b891a085e19ef05e1a529",
     "grade": false,
     "grade_id": "cell-54cb5be6ead8690a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can conclude from the loss curve that we have achieved convergence (the loss has stopped improving), and we can conclude that 3000 iterations is overkill! The loss is stable after 100 iterations or so.\n",
    "\n",
    "### Goodness of fit\n",
    "$R^2$ is a statistic that will give some information about the goodness of fit of a regression model. The $R^2$ coefficient of determination is 1 when the regression predictions perfectly fit the data. When $R^2$ is less than 1, it indicates the percentage of the variance in the target that is accounted for by the prediction.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\ R^2 = 1 - \\frac{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\hat{y}^\\left(i\\right) \\right)^2}\n",
    "{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\bar{y}^\\left(i\\right) \\right)^2}\n",
    "\\end{align}$$\n",
    "\n",
    "### Exercise 6 (2 points)\n",
    "\n",
    "Complete the `goodnees_of_fit` function implementing the equation for $R^2$ above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "407c11e9c6736e6c6588617be56add4b",
     "grade": false,
     "grade_id": "cell-b634b8c95cc9acb4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def goodness_of_fit(y, y_predicted):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a9fc3b54d32243f7a3341e64dc0553c",
     "grade": true,
     "grade_id": "cell-edcf8a1f24f95310",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_predicted =  h(X, theta)\n",
    "r_square = goodness_of_fit(y, y_predicted)\n",
    "print(r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2d1834925e2748c07797ba5a22b369c",
     "grade": false,
     "grade_id": "cell-54ff3695aba46b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**: 0.9786239731773175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fec88473b3c7ea8dfc8ba72661c8e119",
     "grade": false,
     "grade_id": "cell-9eac8f260e7fccf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "An $R^2$ of 0.98 indicates an extremely good (outrageously good, in fact) fit to the data.\n",
    "\n",
    "## Multivariate linear regression example\n",
    "\n",
    "Next, we extend our model to multiple variables. We'll use a data set from Andrew Ng's class. The data include two independent variables,\n",
    "\"Square Feet\" and \"Number of Bedrooms,\" and the dependent variable is \"Price.\"\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use numpy's genfromtxt function to load the data from the text file.\n",
    "\n",
    "raw_data = np.genfromtxt('Housing_data.txt',delimiter = ',', dtype=str);\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b056f86ed3d743714d673834ba9d78d1",
     "grade": false,
     "grade_id": "cell-6de92c1175605f5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we split the raw data (currently strings) into headers and the data themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract headers and data\n",
    "headers = raw_data[0,:];\n",
    "print(headers)\n",
    "data = np.array(raw_data[1:,:], dtype=float);\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of independent and dependent variables\n",
    "\n",
    "# Make three subplots, in one row and three columns\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(20)\n",
    "fig.subplots_adjust(left=.2, bottom=None, right=None, top=None, wspace=.2, hspace=.2)\n",
    "plt1 = plt.subplot(1,3,1)\n",
    "plt2 = plt.subplot(1,3,2)\n",
    "plt3 = plt.subplot(1,3,3)\n",
    "\n",
    "# Variable 1: square footage\n",
    "plt1.hist(data[:,0], label='Sq. feet', edgecolor='black')\n",
    "plt1.set_title('House Size')\n",
    "plt1.set_xlabel('units')\n",
    "plt1.set_ylabel('Frequency')\n",
    "plt1.grid(axis='both', alpha=.25)\n",
    "\n",
    "# Variable 2: number of bedrooms\n",
    "plt2.hist(data[:,1], label='Bedroom', edgecolor='black')\n",
    "plt2.set_title('Bedrooms')\n",
    "plt2.set_xlabel('units')\n",
    "plt2.set_ylabel('Frequency')\n",
    "plt2.grid(axis='both', alpha=.25)\n",
    "\n",
    "# Variable 3: home price\n",
    "plt3.hist(data[:,2], label='Price', edgecolor='black')\n",
    "plt3.set_title('Price')\n",
    "plt3.set_xlabel('units')\n",
    "plt3.set_ylabel('Frequency')\n",
    "plt3.grid(axis='both', alpha=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d6c748cbbf7efee2b942cf50c9c80eb",
     "grade": false,
     "grade_id": "cell-94788fb2b4f2f154",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Normalization\n",
    "\n",
    "We can see from the charts above that the independent variables and the dependent variables have very large differences in their ranges. If you try to use the gradient descent method on these data directly, you may have difficulty in finding a learning rate that is small enough that the costs will not grow out of control but is large enough that the number of iterations is not excessive.\n",
    "\n",
    "Normalization of the independent and dependent variables can help with this.\n",
    "One type of normalization, sometimes called \"standardization\" or \"z-scaling,\"\n",
    "involves subtracting a variable's mean then dividing by its standard deviation,\n",
    "calculated over the training samples. The result is a set of standardized variables,\n",
    "each with a mean of 0 and a variance of 1 over the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "means = np.mean(data, axis=0)\n",
    "stds = np.std(data, axis=0)\n",
    "data_norm = (data - means) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract y from the normalized dataset\n",
    "\n",
    "y_label = 'Price'\n",
    "y_index = np.where(headers == y_label)[0][0]\n",
    "y = np.array([data_norm[:,y_index]]).T\n",
    "\n",
    "# Extract X from normalized dataset\n",
    "\n",
    "X = data_norm[:,0:y_index]\n",
    "\n",
    "# Insert column of 1's for intercept term\n",
    "\n",
    "X = np.insert(X, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of examples (m) and number of parameters (n)\n",
    "m = X.shape[0]\n",
    "n = X.shape[1]\n",
    "print(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ffaf935e0b9d8e2058ff4332097a3f5",
     "grade": false,
     "grade_id": "cell-42dcc4839c98720a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Excercise 7 (5 points)\n",
    "\n",
    "Optimize the parameters using gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54b29c3b2e7053a1b4a460261a062578",
     "grade": false,
     "grade_id": "cell-06acad01684251d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_initial = np.zeros((X.shape[1],1))\n",
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfb07a5a460415b73230d8dc42b9945b",
     "grade": true,
     "grade_id": "cell-2754c18559bfa20d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Theta values ', theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c441594586be4e5fcda8772a5e2e94d",
     "grade": false,
     "grade_id": "cell-85973caececb5438",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:\\\n",
    "Theta values  [[-9.15933995e-17]\\\n",
    " [ 8.84765988e-01]\\\n",
    " [-5.31788197e-02]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss over the optimization\n",
    "plt.title('Multivariate linear regression by gradient descent')\n",
    "cost_plot(iterations, costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c786b12ab0f511c91e9eca0088e98e8",
     "grade": false,
     "grade_id": "cell-ac4e56806eb77334",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Transforming parameters back to the original scale\n",
    "Now that we've got optimal parameters for our original data, we need to undo the normalization.\n",
    "\n",
    "We have\n",
    "\n",
    "$$\\hat{y}^{\\text{norm}} = \\theta^\\text{norm} \\textbf{x}^\\text{norm}$$\n",
    "\n",
    "## Excercise 8 (3 points)\n",
    "\n",
    "Modify the code to compute goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19349ee22d3bf064bd1583cfd248bb79",
     "grade": false,
     "grade_id": "cell-6189182a5a60f3f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Goodness of fit\n",
    "y_predicted = h(X,theta)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3852ac85c56a593c7e9e8cbc3ae5d235",
     "grade": true,
     "grade_id": "cell-6dc4d5d6bc562166",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ff250a5fbab4267e113270985de24d1",
     "grade": false,
     "grade_id": "cell-f19916d1e930779e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Transform standardized data back to original scale\n",
    "We can transform standardized predicted values, y_predicted into the orginal data scale using$$y_{\\text{norm}} = \\sigma_y y + \\mu_y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation of data\n",
    "\n",
    "sigma = np.array(np.std(data,axis=0))\n",
    "mu = np.array(np.mean(data,axis=0))\n",
    "\n",
    "# De-normalize y\n",
    "\n",
    "y_predicted =  np.round(h(X, theta) * sigma[2] + mu[2])\n",
    "\n",
    "# Print first five values of y_predicted\n",
    "\n",
    "print(y_predicted[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot of standardized data\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "p = ax.scatter(X[:,1],X[:,2],y,edgecolors='black',c=data_norm[:,2],alpha=1)\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y')\n",
    "\n",
    "X1 = np.linspace(min(X[:,1]), max(X[:,1]), len(y))\n",
    "X2 = np.linspace(min(X[:,2]), max(X[:,2]), len(y))\n",
    "\n",
    "xx1,xx2 = np.meshgrid(X1,X2)\n",
    "\n",
    "yy = (theta[0] + theta[1]*xx1.T + theta[2]*xx2)\n",
    "ax.plot_surface(xx1,xx2,yy, alpha=0.5)\n",
    "ax.view_init(elev=25, azim=10)\n",
    "plt.colorbar(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17b89e2c0f8597a5cbbd878727828319",
     "grade": false,
     "grade_id": "cell-fd010ec56bee0626",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## In-class exercises\n",
    "Now that you're familiar with minimizing a cost function using its gradient and gradient descent, refer to the lecture notes to find the analytical solution (the normal equations) to the linear regression problem.\n",
    "\n",
    "Implement the normal equation approach for the synthetic univariate data set and the housing price data set. Demonstrate your solution in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d0c78951beda356aa79a2b24f68bd6b",
     "grade": false,
     "grade_id": "cell-e8c0cbe448d8edf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# just remove all parameters\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6561195e6b4fffa7ead553795746357",
     "grade": false,
     "grade_id": "cell-538b321ed5c8c479",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.1 (5 points)\n",
    "Download raw_data and setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6a719be8b093faed7eaa1790daefa52",
     "grade": false,
     "grade_id": "cell-8ec5005213656ad7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Download raw_data and setup data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b46b05c76b940364c581de890670a14",
     "grade": true,
     "grade_id": "cell-684e4a35be532463",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef304895c4b93fac6a63a0d42cbb0773",
     "grade": false,
     "grade_id": "cell-d4ad8dd0267769b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**:\\\n",
    "[[2.104e+03 3.000e+00 3.999e+05]\\\n",
    " [1.600e+03 3.000e+00 3.299e+05]\\\n",
    " [2.400e+03 3.000e+00 3.690e+05]\\\n",
    " [1.416e+03 2.000e+00 2.320e+05]\\\n",
    " [3.000e+03 4.000e+00 5.399e+05]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71cce47ee712c7023136057bf0f6cdc4",
     "grade": false,
     "grade_id": "cell-0859396b500237fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.2 (5 points)\n",
    "Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fff0ffca62d013f2c638b8d9ef8f941",
     "grade": false,
     "grade_id": "cell-0c303e363a86e0e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalized data\n",
    "def normalized_data(data):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b325cf9fcfc0ed6b458b2a69859108c",
     "grade": true,
     "grade_id": "cell-666a35687df87e4b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_norm = normalized_data(data)\n",
    "print(data_norm[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcaae281d6afda1e8fbced4d7ce35f99",
     "grade": false,
     "grade_id": "cell-3ac03ac4ad570ac5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**:\\\n",
    "[[ 0.13141542 -0.22609337  0.48089023]\\\n",
    " [-0.5096407  -0.22609337 -0.08498338]\\\n",
    " [ 0.5079087  -0.22609337  0.23109745]\\\n",
    " [-0.74367706 -1.5543919  -0.87639804]\\\n",
    " [ 1.27107075  1.10220517  1.61263744]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce01cffdfac42022d65b76281810550e",
     "grade": false,
     "grade_id": "cell-283aafc0a867da58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.3 (5 points)\n",
    "Extract X and y from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17668c808a395ad8493df146edd89c32",
     "grade": false,
     "grade_id": "cell-8ffcfa2cd2adaa33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract y from data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "708049b7f3d211152b0cf9bb6d25bbb7",
     "grade": true,
     "grade_id": "cell-b770588a9dedd56d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b677b7a16931c14a73e14ae5400f66b4",
     "grade": false,
     "grade_id": "cell-58b1ba88b8eeaf46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**: [ 0.48089023 -0.08498338  0.23109745 -0.87639804  1.61263744]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0556c13e1431f0a4f425a6b0f9671a46",
     "grade": false,
     "grade_id": "cell-92ceac829e8cb196",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract X from data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bb0f6b8ac5342c1cc64db0d14966a5a",
     "grade": true,
     "grade_id": "cell-717b8a1c64724282",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(X[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "062e393ed04b601f2a7232637cdd65a7",
     "grade": false,
     "grade_id": "cell-a3bc80814584e014",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**:\\\n",
    "[[ 1.          0.13141542 -0.22609337]\\\n",
    " [ 1.         -0.5096407  -0.22609337]\\\n",
    " [ 1.          0.5079087  -0.22609337]\\\n",
    " [ 1.         -0.74367706 -1.5543919 ]\\\n",
    " [ 1.          1.27107075  1.10220517]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "394707bc36f4a53ae79540c55f6e3387",
     "grade": false,
     "grade_id": "cell-fd3883eff0960005",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.4 (8 points)\n",
    "Create h, cost, gradient, and gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "278485d1ffd93167a27411bc45578f82",
     "grade": false,
     "grade_id": "cell-687607f0da0d7abb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create h function\n",
    "def h(X,theta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bd856c7ef5dac04725554fe9c181c1b",
     "grade": true,
     "grade_id": "cell-d957e149102d4dd8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(h(X, np.array([1, 2, 4]))[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d86ada5b79340db17573860dcc5d55e",
     "grade": false,
     "grade_id": "cell-c611d33ee8306391",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**: [ 0.35845737 -0.92365487  1.11144393 -6.70492173  7.95096216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36d1a9a8cacdd113d84e2f273bb40ee3",
     "grade": false,
     "grade_id": "cell-8031aef056c58451",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602e9a565ec8ea14522efe3aee1a6efb",
     "grade": true,
     "grade_id": "cell-13b68cd3acbc1871",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(cost(np.array([1, 8, 10]), X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "803af46d3567fbb30084f1ade1ca3013",
     "grade": false,
     "grade_id": "cell-199d8d7d4540b85e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**: 5477.138628374691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ccd6eb2057e9db1ce6c474d4fa585bc",
     "grade": false,
     "grade_id": "cell-727893bbdd504a71",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of cost function\n",
    "def gradient(X, y, theta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe1d0247f1fb21ae4df649bf8bb4d966",
     "grade": true,
     "grade_id": "cell-8eeb9b2e6bc37c85",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(gradient(X, y, np.array([1, 8, 10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fa0fd23f19d9b4ef7c8b70e6d7ed966",
     "grade": false,
     "grade_id": "cell-58ba3606c3df1a48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**: [ 47.         599.00016917 659.76139633]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e04a59f29703dccb906bee889b50ab6",
     "grade": false,
     "grade_id": "cell-b715505ba6c0fa23",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta_initial, alpha, num_iters):\n",
    "    J_per_iter = np.zeros(num_iters)\n",
    "    gradient_per_iter = np.zeros((num_iters,len(theta_initial)))\n",
    "    # initialize theta\n",
    "    theta = theta_initial\n",
    "    for iter in np.arange(num_iters):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        J_per_iter[iter] = cost(theta, X, y)\n",
    "        gradient_per_iter[iter] = grad.T\n",
    "    return (theta, J_per_iter, gradient_per_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "709f4e1abb895585e1870444ff45f198",
     "grade": true,
     "grade_id": "cell-b60403692e08f361",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(theta, J_per_iter, gradient_per_iter) = gradient_descent(X, y, np.array([0, 1, 10]), 0.001, 10)\n",
    "print(\"theta:\", theta)\n",
    "print(\"J_per_iter:\", J_per_iter)\n",
    "print(\"gradient_per_iter\", gradient_per_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17e4b83ae38f7ce25b89f601b93620c3",
     "grade": false,
     "grade_id": "cell-402bb23146f668b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**:\n",
    "theta: [-8.20787882e-16 -7.72838948e-01  6.35294636e+00]\\\n",
    "J_per_iter: [2123.51284628 1873.56259758 1656.90935568 1468.93187452 1305.65834104\\\n",
    " 1163.67477334 1040.04635308  932.24986509  838.11567544  755.77790087]\\\n",
    "gradient_per_iter [[1.31450406e-13 2.70000169e+02 4.75532186e+02]\\\n",
    " [9.68114477e-14 2.44794887e+02 4.46076185e+02]\\\n",
    " [9.63673585e-14 2.21549490e+02 4.18667980e+02]\\\n",
    " [8.92619312e-14 2.00117968e+02 3.93159744e+02]\\\n",
    " [1.11022302e-13 1.80365065e+02 3.69414440e+02]\\\n",
    " [7.40518757e-14 1.62165488e+02 3.47305031e+02]\\\n",
    " [5.05151476e-14 1.45403177e+02 3.26713748e+02]\\\n",
    " [6.09512441e-14 1.29970626e+02 3.07531415e+02]\\\n",
    " [6.29496455e-14 1.15768253e+02 2.89656812e+02]\\\n",
    " [4.74065232e-14 1.02703825e+02 2.72996100e+02]]\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecbca679d6b7033d2099a5373b2a0d43",
     "grade": false,
     "grade_id": "cell-d727884d390c5e77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.5 (5 points)\n",
    "\n",
    "Do optimization using gradient descent with $\\alpha = 0.003$ and 30,000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c75e9215ce13f5d7f5d4effce1b1ea60",
     "grade": false,
     "grade_id": "cell-bf04058de1bcc1fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7255fb564042d42d2d57850f3b68524",
     "grade": true,
     "grade_id": "cell-a940fb3166647683",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"theta:\", theta)\n",
    "print(\"cost_per_iter:\", costs[-5:])\n",
    "print(\"gradient_per_iter\", grad[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5083dc54cc6c769e39ad24533b06dfd8",
     "grade": false,
     "grade_id": "cell-3ae5422c1168d02d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**:\\\n",
    "theta: [-1.05832010e-16  8.84765988e-01 -5.31788197e-02]\\\n",
    "J_per_iter: [6.27579208 6.27579208 6.27579208 6.27579208 6.27579208]\\\n",
    "gradient_per_iter [[ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]\\\n",
    " [ 0.00000000e+00 -1.72082220e-14  8.75724041e-16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21fa0e0faee56552a8a0d1a04e40429c",
     "grade": false,
     "grade_id": "cell-8ccc1a736758244e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.6 (2 points)\n",
    "\n",
    "Calculate goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "238059b37180f37a8790560546c5a01e",
     "grade": false,
     "grade_id": "cell-5d3692752f6fbab2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def goodness_of_fit(y, y_predicted):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2449e3273ed79b56ac45914381900b4a",
     "grade": true,
     "grade_id": "cell-f772768c21ce0ea6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_predicted =  h(X, theta)\n",
    "r_square = goodness_of_fit(y, y_predicted)\n",
    "print(r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9328d4d810b5473406eaa138cbbfbde",
     "grade": false,
     "grade_id": "cell-222da897ae9c62bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**: 0.7329450180289143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "321fc8eadb95a2c82541b47082971195",
     "grade": false,
     "grade_id": "cell-4a1c9001937ca857",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Excercise 2.7 (2 point)\n",
    "\n",
    "Plot graph of cost results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdd8f8022997cb5611b74deec9006da4",
     "grade": true,
     "grade_id": "cell-b4869512362ab6cd",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost_plot(iterations, costs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "cost_plot(iterations, costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "024e2cc1ed88d569fc772d75645e2995",
     "grade": false,
     "grade_id": "cell-05006048af4fd496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.8 (8 points)\n",
    "\n",
    "Write a function implementing the normal equations for linear equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f72084001d616cf35839ab957d4a5b1f",
     "grade": false,
     "grade_id": "cell-613b033259c6ef42",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to use the normal equations to find the optimal\n",
    "# parameters for a linear regression model\n",
    "\n",
    "def normal_equation(X, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb9fbb2ef03a49a037f0ed7570606b5d",
     "grade": true,
     "grade_id": "cell-3f75014dc83a1372",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta_norm = normal_equation(X,np.array([y]).T)\n",
    "print(\"theta from normal equation:\", theta_norm.T)\n",
    "y_norm_predicted =  h(X, theta_norm)\n",
    "r_norm_square = goodness_of_fit(y, y_norm_predicted)\n",
    "print(\"r_square:\", r_norm_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "538ddf99261575fb9fc77d5710cd156e",
     "grade": false,
     "grade_id": "cell-160c14bd432b8075",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**:\\\n",
    "theta from normal equation: [[-7.90434550e-17  8.84765988e-01 -5.31788197e-02]]\\\n",
    "r_square: 0.7329450180289143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eafbc6ab4fe63d5b817b7dba7b9e1a9e",
     "grade": false,
     "grade_id": "cell-0c27f43b5c40a687",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Take-home exercise (40 points)\n",
    "Find an interesting dataset for linear regression on Kaggle. Implement the normal equations and gradient descent then evaluate your model's performance.\n",
    "\n",
    "Write a brief report on your experiments and results in the form of a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "315b77ce9d9b39f9cf76936a6e4e2ddb",
     "grade": false,
     "grade_id": "cell-97cac4f2657fe8e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Explain the dataset which you get and which rows which you use.\n",
    "How many data in your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fdc116ce5f8e958dd37874cda253742",
     "grade": true,
     "grade_id": "cell-fc743a8c603c95fb",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2da20c2ecc97760cb3843751df5edb9c",
     "grade": false,
     "grade_id": "cell-16cb90ab7980490c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write down your all code at below.\n",
    "Show the results, goodness of fit and plot cost graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9465e8d65b68a77ec06a53b9023dcef5",
     "grade": true,
     "grade_id": "cell-54284c2d3a5a5544",
     "locked": false,
     "points": 35,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
