{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick linear regression tutorial with numpy\n",
    "\n",
    "This is a quick tutorial in doing linear regression models\n",
    "with numpy and checking the correctness of the result of\n",
    "a machine learning experiment.\n",
    "\n",
    "For any supervised learning experiment, we need\n",
    "\n",
    "1. A data set with matched input-output pairs $\\{ (\\mathbf{x}^{(1)}, y^{(1)}), \\ldots, (\\mathbf{x}^{(m)}, y^{(m)}) \\}$ ;\n",
    "2. A model (a mathematical equation for the hypothesis $h_{\\mathbf{\\theta}}(\\mathbf{x})$;\n",
    "3. A loss function ${\\cal L}(\\mathbf{\\theta}, \\mathtt{X}, \\mathbf{y})$.\n",
    "\n",
    "In the case of linear regression, the model is $$ h_{\\mathbf{\\theta}}(\\mathbf{x}) = \\theta_0 + \\theta_1 x_1 + \\cdots + \\theta_n x_n . $$\n",
    "and the loss function is $$ {\\cal L}(\\mathbf{\\theta}, \\mathtt{X}, \\mathbf{y}) = \\frac{1}{2} \\sum_{i=1}^m \\left(h_{\\mathbf{\\theta}}(\\mathbf{x}^{(i)})-y^{(i)}\\right)^2 .$$\n",
    "If we arrange the data into matrices as\n",
    "$$\\mathtt{X} = \\begin{bmatrix} 1 & x_1^{(1)} & \\cdots & x_n^{(1)} \\\\\n",
    "                               \\vdots & \\vdots & & \\vdots \\\\\n",
    "                               1 & x_1^{(m)} & \\cdots & x_n^{(m)} \\end{bmatrix}, \\;\\;\\;\\;\n",
    "                               \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}, $$\n",
    "then the optimal parameters are\n",
    "$$\\mathbf{\\theta}^* = (\\mathtt{X}^{\\top} \\mathtt{X})^{-1} \\mathtt{X}^{\\top} \\mathbf{y} $$\n",
    "(the normal equations).\n",
    "\n",
    "In the code below, we synthesize a sample data set comprising $\\mathtt{X}$ and $\\mathbf{y}$, calculate\n",
    "$\\mathbf{\\theta}^*$, compare the loss based on the optimal and ground truth parameters, then verify that\n",
    "$\\mathbf{\\theta}^*$ is approximately a minimum of the loss function using finite differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters: -119.438905, 1.107040\n",
      "Loss with ground truth theta: 50262.681165\n",
      "Loss with estimated theta: 49429.429425\n",
      "Gradient estimate: 0.000073, 0.271903\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ground truth parameters\n",
    "\n",
    "theta0 = -100\n",
    "theta1 = 1\n",
    "sigma = 10\n",
    "\n",
    "# Generate training dataset using ground truth\n",
    "\n",
    "m = 100\n",
    "\n",
    "# X: m samples from a Gaussian with mean 160 and standard deviation of 20\n",
    "\n",
    "X = np.matrix(np.random.normal(160, 20, m)).T\n",
    "X = np.concatenate([np.ones([m,1]),X],1)\n",
    "\n",
    "# y: m samples from a Gaussian with mean theta0 + theta1 x, std of sigma\n",
    "\n",
    "theta = np.matrix([ theta0, theta1 ]).T\n",
    "y = X * theta + np.random.normal(0, 20, [m,1])\n",
    "\n",
    "# Estimate a linear model\n",
    "\n",
    "theta_est = np.linalg.inv(X.T*X) * X.T * y\n",
    "\n",
    "print('Estimated parameters: %f, %f' % (theta_est[0], theta_est[1]))\n",
    "\n",
    "def loss(X, y, theta):\n",
    "    error = y - X * theta\n",
    "    error = error.T * error\n",
    "    return error\n",
    "    \n",
    "lgt = loss(X, y, theta)\n",
    "print(\"Loss with ground truth theta: %f\" % lgt)\n",
    "lest = loss(X, y, theta_est)\n",
    "print(\"Loss with estimated theta: %f\" % lest)\n",
    "\n",
    "# Verify result using finite differences\n",
    "\n",
    "deltaTheta = 0.0000001\n",
    "\n",
    "# Parameter theta0\n",
    "thetaNew = theta_est + np.matrix([ deltaTheta, 0 ]).T\n",
    "lnew0 = loss(X, y, thetaNew)\n",
    "grad0est = (lnew0 - lest) / deltaTheta\n",
    "\n",
    "# Parameter theta1\n",
    "thetaNew = theta_est + np.matrix([ 0, deltaTheta ]).T\n",
    "lnew1 = loss(X, y, thetaNew)\n",
    "grad1est = (lnew1 - lest) / deltaTheta\n",
    "\n",
    "print('Gradient estimate: %f, %f' % (grad0est, grad1est))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
